(* Module for axiomatizing type "integer", created in Gnat2Why.Types.Translate_Type *)
module Standard__integer
  
  use import _gnatprove_standard.Main
  use import int.Int
  use import int.Int
  
  type integer  = <range -2147483648 2147483647>
  
  function   first () requires { True } ensures  { True } returns
    int = -2147483648
  
  function   last () requires { True } ensures  { True } returns
    int = 2147483647
  
  function   in_range (x : int) requires { True } ensures  { True } returns
     = ((first <= x) /\ (x <= last))
  
  clone export ada__model.Static_Discrete with axiom . type t = integer,
    function first = first, function last = last,
    predicate in_range = in_range
  
  type integer__ref  = { mutable integer__content : integer }
  
  function   integer__ref_integer__content__projection (a : integer__ref)
    requires {  } ensures  {  } returns integer = a.integer__content
  
  meta model_projection function integer__ref_integer__content__projection
  
  meta inline:no function integer__ref_integer__content__projection
  
  function   integer__havoc (x : integer__ref) requires {  } ensures  {  }
    returns unit

end

(* Module giving axioms for type "integer", created in Gnat2Why.Types.Generate_Type_Completion *)
module Standard__integer___axiom
  
  use import _gnatprove_standard.Main
  use import int.Int
  use import int.Int
  use        Standard__integer
  
  function   dynamic_invariant
    (([mlw:proxy_symbol] [introduced] temp___expr_18) : int
    ([mlw:proxy_symbol] [introduced] temp___is_init_14) : bool
    ([mlw:proxy_symbol] [introduced] temp___skip_constant_15) : bool
    ([mlw:proxy_symbol] [introduced] temp___do_toplevel_16) : bool
    ([mlw:proxy_symbol] [introduced] temp___do_typ_inv_17) : bool) requires
    { True } ensures  { True } returns
     = (if
       ((([mlw:proxy_symbol] [introduced] temp___is_init_14) = True) \/
          (Standard__integer.first <= Standard__integer.last))
       then
       (Standard__integer.dynamic_property Standard__integer.first
          Standard__integer.last ([mlw:proxy_symbol]
          [introduced] temp___expr_18))
       )
  
  function   default_initial_assumption
    (([mlw:proxy_symbol] [introduced] temp___expr_19) : int
    ([mlw:proxy_symbol] [introduced] temp___skip_top_level_20) : bool)
    requires { True } ensures  { True } returns  = True

end

(* Module for axiomatizing type "natural", created in Gnat2Why.Types.Translate_Type *)
module Standard__natural
  
  use import _gnatprove_standard.Main
  use import int.Int
  use import int.Int
  
  type natural  = <range 0 2147483647>
  
  function   first () requires { True } ensures  { True } returns int = 0
  
  function   last () requires { True } ensures  { True } returns
    int = 2147483647
  
  function   in_range (x : int) requires { True } ensures  { True } returns
     = ((first <= x) /\ (x <= last))
  
  clone export ada__model.Static_Discrete with axiom . type t = natural,
    function first = first, function last = last,
    predicate in_range = in_range
  
  type natural__ref  = { mutable natural__content : natural }
  
  function   natural__ref_natural__content__projection (a : natural__ref)
    requires {  } ensures  {  } returns natural = a.natural__content
  
  meta model_projection function natural__ref_natural__content__projection
  
  meta inline:no function natural__ref_natural__content__projection
  
  function   natural__havoc (x : natural__ref) requires {  } ensures  {  }
    returns unit

end

(* Module giving axioms for type "natural", created in Gnat2Why.Types.Generate_Type_Completion *)
module Standard__natural___axiom
  
  use import _gnatprove_standard.Main
  use import int.Int
  use import int.Int
  use        Standard__natural
  
  function   dynamic_invariant
    (([mlw:proxy_symbol] [introduced] temp___expr_46) : int
    ([mlw:proxy_symbol] [introduced] temp___is_init_42) : bool
    ([mlw:proxy_symbol] [introduced] temp___skip_constant_43) : bool
    ([mlw:proxy_symbol] [introduced] temp___do_toplevel_44) : bool
    ([mlw:proxy_symbol] [introduced] temp___do_typ_inv_45) : bool) requires
    { True } ensures  { True } returns
     = (if
       ((([mlw:proxy_symbol] [introduced] temp___is_init_42) = True) \/
          (Standard__natural.first <= Standard__natural.last))
       then
       (Standard__natural.dynamic_property Standard__natural.first
          Standard__natural.last ([mlw:proxy_symbol]
          [introduced] temp___expr_46))
       )
  
  function   default_initial_assumption
    (([mlw:proxy_symbol] [introduced] temp___expr_47) : int
    ([mlw:proxy_symbol] [introduced] temp___skip_top_level_48) : bool)
    requires { True } ensures  { True } returns  = True

end

(* Module defining to_rep/of_rep for type "natural", created in Gnat2Why.Types.Translate_Type *)
module Standard__natural__rep
  
  use        Standard__natural
  use import _gnatprove_standard.Main
  use import int.Int
  
  function   to_rep (x : Standard__natural.natural) requires { True }
    ensures  { True } returns int = (Standard__natural.natural'int x)
  
  clone export ada__model.Rep_Proj_Int with axiom . type t = Standard__natural.natural,
    predicate in_range = Standard__natural.in_range, function to_rep = to_rep
  
  meta model_projection function to_rep
  
  meta inline:no function to_rep

end

(* Module for axiomatizing type "positive", created in Gnat2Why.Types.Translate_Type *)
module Standard__positive
  
  use import _gnatprove_standard.Main
  use import int.Int
  use import int.Int
  
  type positive  = <range 1 2147483647>
  
  function   first () requires { True } ensures  { True } returns int = 1
  
  function   last () requires { True } ensures  { True } returns
    int = 2147483647
  
  function   in_range (x : int) requires { True } ensures  { True } returns
     = ((first <= x) /\ (x <= last))
  
  clone export ada__model.Static_Discrete with axiom . type t = positive,
    function first = first, function last = last,
    predicate in_range = in_range
  
  type positive__ref  = { mutable positive__content : positive }
  
  function   positive__ref_positive__content__projection (a : positive__ref)
    requires {  } ensures  {  } returns positive = a.positive__content
  
  meta model_projection function positive__ref_positive__content__projection
  
  meta inline:no function positive__ref_positive__content__projection
  
  function   positive__havoc (x : positive__ref) requires {  } ensures  {  }
    returns unit

end

(* Module giving axioms for type "positive", created in Gnat2Why.Types.Generate_Type_Completion *)
module Standard__positive___axiom
  
  use import _gnatprove_standard.Main
  use import int.Int
  use import int.Int
  use        Standard__positive
  
  function   dynamic_invariant
    (([mlw:proxy_symbol] [introduced] temp___expr_53) : int
    ([mlw:proxy_symbol] [introduced] temp___is_init_49) : bool
    ([mlw:proxy_symbol] [introduced] temp___skip_constant_50) : bool
    ([mlw:proxy_symbol] [introduced] temp___do_toplevel_51) : bool
    ([mlw:proxy_symbol] [introduced] temp___do_typ_inv_52) : bool) requires
    { True } ensures  { True } returns
     = (if
       ((([mlw:proxy_symbol] [introduced] temp___is_init_49) = True) \/
          (Standard__positive.first <= Standard__positive.last))
       then
       (Standard__positive.dynamic_property Standard__positive.first
          Standard__positive.last ([mlw:proxy_symbol]
          [introduced] temp___expr_53))
       )
  
  function   default_initial_assumption
    (([mlw:proxy_symbol] [introduced] temp___expr_54) : int
    ([mlw:proxy_symbol] [introduced] temp___skip_top_level_55) : bool)
    requires { True } ensures  { True } returns  = True

end

(* Module defining to_rep/of_rep for type "positive", created in Gnat2Why.Types.Translate_Type *)
module Standard__positive__rep
  
  use        Standard__positive
  use import _gnatprove_standard.Main
  use import int.Int
  
  function   to_rep (x : Standard__positive.positive) requires { True }
    ensures  { True } returns int = (Standard__positive.positive'int x)
  
  clone export ada__model.Rep_Proj_Int with axiom . type t = Standard__positive.positive,
    predicate in_range = Standard__positive.in_range,
    function to_rep = to_rep
  
  meta model_projection function to_rep
  
  meta inline:no function to_rep

end

(* Module for axiomatizing type "character", created in Gnat2Why.Types.Translate_Type *)
module Standard__character
  
  use import _gnatprove_standard.Main
  use import int.Int
  use import int.Int
  
  type character  
  
  function   first () requires { True } ensures  { True } returns int = 0
  
  function   last () requires { True } ensures  { True } returns int = 255
  
  function   in_range (x : int) requires { True } ensures  { True } returns
     = ((first <= x) /\ (x <= last))
  
  clone export ada__model.Static_Discrete with axiom . type t = character,
    function first = first, function last = last,
    predicate in_range = in_range
  
  type character__ref  = { mutable character__content : character }
  
  function   character__ref_character__content__projection
    (a : character__ref) requires {  } ensures  {  } returns
    character = a.character__content
  
  meta model_projection function character__ref_character__content__projection
  
  meta inline:no function character__ref_character__content__projection
  
  function   character__havoc (x : character__ref) requires {  } ensures 
    {  } returns unit

end

(* Module defining to_rep/of_rep for type "character", created in Gnat2Why.Types.Translate_Type *)
module Standard__character__rep
  
  use        Standard__character
  use import _gnatprove_standard.Main
  use import int.Int
  
  clone export ada__model.Rep_Proj_Int with axiom . type t = Standard__character.character,
    predicate in_range = Standard__character.in_range
  
  meta model_projection function to_rep
  
  meta inline:no function to_rep

end

(* Module for axiomatizing the array theory associated to type "string", created in Why.Gen.Arrays.Create_Rep_Array_Theory *)
module Array__Int__Standard__character
  
  use import _gnatprove_standard.Main
  use import int.Int
  use import int.Int
  use        Standard__character
  use        Standard__character__rep
  
  function   index_I1_one () requires { True } ensures  { True } returns
    int = 1
  
  type component_type  = --pp_transparent_type_definition NOT IMPLEMENTED
  
  clone export _gnatprove_standard.Array__1 with axiom . type I1.t = int,
    predicate I1.le = <=, predicate I1.lt = <, predicate I1.gt = >,
    function I1.add = +, function I1.sub = -, function I1.one = index_I1_one,
    type component_type = component_type
  
  function   bool_eq
    (a : map a__first : int a__last : int b : map b__first : int
    b__last : int) requires { True } ensures  { True } returns
    bool = ((if (a__first <= a__last) then
            ((b__first <= b__last) /\
               ((a__last - a__first) = (b__last - b__first)))
             else (b__first > b__last)) /\
              --pp_universal_quantif NOT IMPLEMENTED)
  
  axiom bool_eq_rev : --pp_universal_quantif NOT IMPLEMENTED

end

(* Module defining to_rep/of_rep for type "integer", created in Gnat2Why.Types.Translate_Type *)
module Standard__integer__rep
  
  use        Standard__integer
  use import _gnatprove_standard.Main
  use import int.Int
  
  function   to_rep (x : Standard__integer.integer) requires { True }
    ensures  { True } returns int = (Standard__integer.integer'int x)
  
  clone export ada__model.Rep_Proj_Int with axiom . type t = Standard__integer.integer,
    predicate in_range = Standard__integer.in_range, function to_rep = to_rep
  
  meta model_projection function to_rep
  
  meta inline:no function to_rep

end

(* Module for axiomatizing type "string", created in Gnat2Why.Types.Translate_Type *)
module Standard__string
  
  use import _gnatprove_standard.Main
  use import int.Int
  use import int.Int
  use        Standard__integer
  use        Standard__positive
  use        Standard__character
  use        Array__Int__Standard__character
  use        Standard__integer__rep
  
  type component_type  = --pp_transparent_type_definition NOT IMPLEMENTED
  
  function   index_1_id (x : int) requires { True } ensures  { True } returns
    int = x
  
  clone export ada__model.Unconstr_Array with axiom . type map = Array__Int__Standard__character.map,
    function array_bool_eq = Array__Int__Standard__character.bool_eq,
    type index_base_type = Standard__integer.integer,
    type index_rep_type = int,
    function to_rep = Standard__integer__rep.to_rep,
    function rep_to_int = index_1_id,
    predicate in_range_base = Standard__integer.in_range,
    predicate index_dynamic_property = Standard__positive.dynamic_property,
    predicate index_rep_le = <=
  
  type string__  = --pp_transparent_type_definition NOT IMPLEMENTED
  
  meta model_projection function to_array
  
  meta inline:no function to_array
  
  meta model_projection function first
  
  meta inline:no function first
  
  meta model_projection function last
  
  meta inline:no function last
  
  type string____ref  = { mutable string____content : string__ }
  
  function   string____ref_string____content__projection (a : string____ref)
    requires {  } ensures  {  } returns string__ = a.string____content
  
  meta model_projection function string____ref_string____content__projection
  
  meta inline:no function string____ref_string____content__projection
  
  function   string____havoc (x : string____ref) requires {  } ensures  {  }
    returns unit

end

(* Module giving axioms for type "string", created in Gnat2Why.Types.Generate_Type_Completion *)
module Standard__string___axiom
  
  use import _gnatprove_standard.Main
  use import int.Int
  use        Standard__positive
  use        Standard__string
  
  function   dynamic_invariant
    (([mlw:proxy_symbol]
    [introduced] temp___expr_103) : Standard__string.string__
    ([mlw:proxy_symbol] [introduced] temp___is_init_99) : bool
    ([mlw:proxy_symbol] [introduced] temp___skip_constant_100) : bool
    ([mlw:proxy_symbol] [introduced] temp___do_toplevel_101) : bool
    ([mlw:proxy_symbol] [introduced] temp___do_typ_inv_102) : bool) requires
    { True } ensures  { True } returns
     = (if ([mlw:proxy_symbol] [introduced] temp___skip_constant_100) then
       True  else
       (Standard__string.dynamic_property Standard__positive.first
          Standard__positive.last
          (Standard__string.first ([mlw:proxy_symbol]
             [introduced] temp___expr_103))
          (Standard__string.last ([mlw:proxy_symbol]
             [introduced] temp___expr_103))))

end

(* Module for possibly declaring a logic function for "is_whitespace" defined at mystringtokeniser.ads:12, created in Gnat2Why.Subprograms.Translate_Subprogram_Spec *)
module Mystringtokeniser__is_whitespace
  
  use import _gnatprove_standard.Main
  use import int.Int
  
  function   is_whitespace (ch : int) requires { True } ensures  { True }
    returns bool
  
  function   is_whitespace__function_guard
    (([mlw:proxy_symbol] [introduced] temp___result_162) : bool ch : int)
    requires { True } ensures  { True } returns bool

end

(* Module giving axioms for type "character", created in Gnat2Why.Types.Generate_Type_Completion *)
module Standard__character___axiom
  
  use import _gnatprove_standard.Main
  use import int.Int
  use import int.Int
  use        Standard__character
  
  function   dynamic_invariant
    (([mlw:proxy_symbol] [introduced] temp___expr_81) : int
    ([mlw:proxy_symbol] [introduced] temp___is_init_77) : bool
    ([mlw:proxy_symbol] [introduced] temp___skip_constant_78) : bool
    ([mlw:proxy_symbol] [introduced] temp___do_toplevel_79) : bool
    ([mlw:proxy_symbol] [introduced] temp___do_typ_inv_80) : bool) requires
    { True } ensures  { True } returns
     = (if
       ((([mlw:proxy_symbol] [introduced] temp___is_init_77) = True) \/
          (Standard__character.first <= Standard__character.last))
       then
       (Standard__character.dynamic_property Standard__character.first
          Standard__character.last ([mlw:proxy_symbol]
          [introduced] temp___expr_81))
       )
  
  function   default_initial_assumption
    (([mlw:proxy_symbol] [introduced] temp___expr_82) : int
    ([mlw:proxy_symbol] [introduced] temp___skip_top_level_83) : bool)
    requires { True } ensures  { True } returns  = True

end

(* Module giving a program function and a defining axiom for the expression function "is_whitespace" defined at mystringtokeniser.ads:12, created in Gnat2Why.Subprograms.Translate_Expression_Function_Body *)
module Mystringtokeniser__is_whitespace___axiom
  
  use import _gnatprove_standard.Main
  use import int.Int
  use import int.Int
  use        Standard__character___axiom
  use        Mystringtokeniser__is_whitespace
  
  function   is_whitespace (ch : int) requires { True } ensures 
    { ((result = (Mystringtokeniser__is_whitespace.is_whitespace ch)) /\
         (Mystringtokeniser__is_whitespace.is_whitespace__function_guard
            result ch) /\ (result = (((ch = 32) \/ (ch = 10)) \/ (ch = 9)))) }
    returns bool
  
  axiom is_whitespace__post_axiom : --pp_universal_quantif NOT IMPLEMENTED
  
  axiom is_whitespace__def_axiom : --pp_universal_quantif NOT IMPLEMENTED

end

(* Module for defining the constant "s" defined at mystringtokeniser.ads:16, created in Gnat2Why.Decls.Translate_Constant *)
module Mystringtokeniser__tokenise__s
  
  use import _gnatprove_standard.Main
  use import int.Int
  use        Standard__string
  
  function [model_projected] [name:S] [model_trace:1167]
    [sloc:mystringtokeniser.ads:16] s () requires {  } ensures  {  } returns
    Standard__string.string__

end

(* Module for axiomatizing the record theory associated to type "tokenextent" defined at mystringtokeniser.ads:5, created in Why.Gen.Records.Create_Rep_Record_Theory_If_Needed *)
module Mystringtokeniser__tokenextent__rep
  
  use import _gnatprove_standard.Main
  use import int.Int
  use        Standard__natural
  use        Standard__natural__rep
  use        Standard__positive
  use        Standard__positive__rep
  
  type __split_fields  = { [model_trace:.1119]
                           [name:Start]rec__mystringtokeniser__tokenextent__start : Standard__positive.positive;
                           [model_trace:.1124]
                           [name:Length]rec__mystringtokeniser__tokenextent__length : Standard__natural.natural }
  
  function [model_trace:.1119] [name:Start] 
    __split_fields_rec__mystringtokeniser__tokenextent__start__projection
    (a : __split_fields) requires {  } ensures  {  } returns
    Standard__positive.positive = a.rec__mystringtokeniser__tokenextent__start
  
  meta model_projection function __split_fields_rec__mystringtokeniser__tokenextent__start__projection
  
  meta inline:no function __split_fields_rec__mystringtokeniser__tokenextent__start__projection
  
  function [model_trace:.1124] [name:Length] 
    __split_fields_rec__mystringtokeniser__tokenextent__length__projection
    (a : __split_fields) requires {  } ensures  {  } returns
    Standard__natural.natural = a.rec__mystringtokeniser__tokenextent__length
  
  meta model_projection function __split_fields_rec__mystringtokeniser__tokenextent__length__projection
  
  meta inline:no function __split_fields_rec__mystringtokeniser__tokenextent__length__projection
  
  type __split_fields__ref  = { mutable __split_fields__content : __split_fields }
  
  function   __split_fields__ref___split_fields__content__projection
    (a : __split_fields__ref) requires {  } ensures  {  } returns
    __split_fields = a.__split_fields__content
  
  meta model_projection function __split_fields__ref___split_fields__content__projection
  
  meta inline:no function __split_fields__ref___split_fields__content__projection
  
  function   __split_fields__havoc (x : __split_fields__ref) requires {  }
    ensures  {  } returns unit
  
  type __rep  = { __split_fields : __split_fields }
  
  function   __rep___split_fields__projection (a : __rep) requires {  }
    ensures  {  } returns __split_fields = a.__split_fields
  
  meta model_projection function __rep___split_fields__projection
  
  meta inline:no function __rep___split_fields__projection
  
  function   to_base (a : __rep) requires { True } ensures  { True } returns
    __rep = a
  
  function   of_base (a : __rep) requires { True } ensures  { True } returns
    __rep = a
  
  function   mystringtokeniser__tokenextent__start__pred (a : __rep) requires
    { True } ensures  { True } returns  = True
  
  function   rec__mystringtokeniser__tokenextent__start_ (a : __rep) requires
    { (mystringtokeniser__tokenextent__start__pred a) } ensures 
    { (result = a.__split_fields.rec__mystringtokeniser__tokenextent__start) }
    returns Standard__positive.positive
  
  function   mystringtokeniser__tokenextent__length__pred (a : __rep)
    requires { True } ensures  { True } returns  = True
  
  function   rec__mystringtokeniser__tokenextent__length_ (a : __rep)
    requires { (mystringtokeniser__tokenextent__length__pred a) } ensures 
    { (result = a.__split_fields.rec__mystringtokeniser__tokenextent__length) }
    returns Standard__natural.natural
  
  function   bool_eq (a : __rep b : __rep) requires { True } ensures 
    { True } returns
    bool = (if
           (((Standard__positive__rep.to_rep
                a.__split_fields.rec__mystringtokeniser__tokenextent__start)
               = (Standard__positive__rep.to_rep
                    b.__split_fields.rec__mystringtokeniser__tokenextent__start))
              /\
              ((Standard__natural__rep.to_rep
                  a.__split_fields.rec__mystringtokeniser__tokenextent__length)
                 = (Standard__natural__rep.to_rep
                      b.__split_fields.rec__mystringtokeniser__tokenextent__length)))
           then True  else False)

end

(* Module for axiomatizing type "tokenextent" defined at mystringtokeniser.ads:5, created in Gnat2Why.Types.Translate_Type *)
module Mystringtokeniser__tokenextent
  
  use export Mystringtokeniser__tokenextent__rep
  use import _gnatprove_standard.Main
  use import int.Int
  use import int.Int
  
  type tokenextent  = --pp_transparent_type_definition NOT IMPLEMENTED
  
  function   value__size () requires {  } ensures  {  } returns int
  
  function   object__size () requires {  } ensures  {  } returns int
  
  function   alignment () requires {  } ensures  {  } returns int
  
  axiom value__size_axiom : ((value__size ) >= 0)
  
  axiom object__size_axiom : ((object__size ) >= 0)
  
  axiom alignment_axiom : ((alignment ) >= 0)
  
  function   mystringtokeniser__tokenextent__start__first__bit () requires
    {  } ensures  {  } returns int
  
  function   mystringtokeniser__tokenextent__start__last__bit () requires
    {  } ensures  {  } returns int
  
  function   mystringtokeniser__tokenextent__start__position () requires {  }
    ensures  {  } returns int
  
  axiom mystringtokeniser__tokenextent__start__first__bit_axiom : ((mystringtokeniser__tokenextent__start__first__bit
                                                                    ) >= 0)
  
  axiom mystringtokeniser__tokenextent__start__last__bit_axiom : ((mystringtokeniser__tokenextent__start__last__bit
                                                                    )
                                                                    > (
                                                                    mystringtokeniser__tokenextent__start__first__bit
                                                                    ))
  
  axiom mystringtokeniser__tokenextent__start__position_axiom : ((mystringtokeniser__tokenextent__start__position
                                                                    ) >= 0)
  
  function   mystringtokeniser__tokenextent__length__first__bit () requires
    {  } ensures  {  } returns int
  
  function   mystringtokeniser__tokenextent__length__last__bit () requires
    {  } ensures  {  } returns int
  
  function   mystringtokeniser__tokenextent__length__position () requires
    {  } ensures  {  } returns int
  
  axiom mystringtokeniser__tokenextent__length__first__bit_axiom : ((mystringtokeniser__tokenextent__length__first__bit
                                                                    ) >= 0)
  
  axiom mystringtokeniser__tokenextent__length__last__bit_axiom : ((mystringtokeniser__tokenextent__length__last__bit
                                                                    )
                                                                    > (
                                                                    mystringtokeniser__tokenextent__length__first__bit
                                                                    ))
  
  axiom mystringtokeniser__tokenextent__length__position_axiom : ((mystringtokeniser__tokenextent__length__position
                                                                    ) >= 0)
  
  function   user_eq (a : tokenextent b : tokenextent) requires { True }
    ensures  { True } returns bool
  
  function   dummy () requires {  } ensures  {  } returns tokenextent
  
  type tokenextent__ref  = { mutable tokenextent__content : tokenextent }
  
  function   tokenextent__ref_tokenextent__content__projection
    (a : tokenextent__ref) requires {  } ensures  {  } returns
    tokenextent = a.tokenextent__content
  
  meta model_projection function tokenextent__ref_tokenextent__content__projection
  
  meta inline:no function tokenextent__ref_tokenextent__content__projection
  
  function   tokenextent__havoc (x : tokenextent__ref) requires {  } ensures 
    {  } returns unit

end

(* Module for axiomatizing the array theory associated to type "tokenarray" defined at mystringtokeniser.ads:10, created in Why.Gen.Arrays.Create_Rep_Array_Theory *)
module Array__Int__Mystringtokeniser__tokenextent
  
  use import _gnatprove_standard.Main
  use import int.Int
  use import int.Int
  use        Mystringtokeniser__tokenextent
  
  function   index_I1_one () requires { True } ensures  { True } returns
    int = 1
  
  type component_type  = --pp_transparent_type_definition NOT IMPLEMENTED
  
  clone export _gnatprove_standard.Array__1 with axiom . type I1.t = int,
    predicate I1.le = <=, predicate I1.lt = <, predicate I1.gt = >,
    function I1.add = +, function I1.sub = -, function I1.one = index_I1_one,
    type component_type = component_type
  
  function   bool_eq
    (a : map a__first : int a__last : int b : map b__first : int
    b__last : int) requires { True } ensures  { True } returns
    bool = ((if (a__first <= a__last) then
            ((b__first <= b__last) /\
               ((a__last - a__first) = (b__last - b__first)))
             else (b__first > b__last)) /\
              --pp_universal_quantif NOT IMPLEMENTED)
  
  axiom bool_eq_rev : --pp_universal_quantif NOT IMPLEMENTED

end

(* Module for defining a ref holding the value of variable "tokens" defined at mystringtokeniser.ads:16, created in Gnat2Why.Decls.Translate_Variable *)
module Mystringtokeniser__tokenise__tokens
  
  use import _gnatprove_standard.Main
  use import int.Int
  use        Standard__integer
  use        Array__Int__Mystringtokeniser__tokenextent
  
  val tokens [name:Tokens] [model_projected]
  [model_trace:1170] [sloc:mystringtokeniser.ads:16]: Array__Int__Mystringtokeniser__tokenextent.map
  
  function [name:Tokens] [model_projected] [model_trace:1170'First]
    [sloc:mystringtokeniser.ads:16] tokens__first () requires {  } ensures 
    {  } returns Standard__integer.integer
  
  function [name:Tokens] [model_projected] [model_trace:1170'Last]
    [sloc:mystringtokeniser.ads:16] tokens__last () requires {  } ensures 
    {  } returns Standard__integer.integer

end

(* Module for defining a ref holding the value of variable "count" defined at mystringtokeniser.ads:16, created in Gnat2Why.Decls.Translate_Variable *)
module Mystringtokeniser__tokenise__count
  
  use import _gnatprove_standard.Main
  use import int.Int
  
  val count [model_projected] [model_trace:1173]
  [name:Count] [sloc:mystringtokeniser.ads:16]: int

end

(* Module for defining a ref holding the value of variable "index" defined at mystringtokeniser.adb:7, created in Gnat2Why.Decls.Translate_Variable *)
module Mystringtokeniser__tokenise__index
  
  use import _gnatprove_standard.Main
  use import int.Int
  
  val index [model_projected] [name:Index]
  [model_trace:832] [sloc:mystringtokeniser.adb:7]: int

end

(* Module for defining a ref holding the value of variable "extent" defined at mystringtokeniser.adb:8, created in Gnat2Why.Decls.Translate_Variable *)
module Mystringtokeniser__tokenise__extent
  
  use import _gnatprove_standard.Main
  use import int.Int
  use        Mystringtokeniser__tokenextent
  
  val extent__split_fields [model_projected] [name:Extent]
  [model_trace:836] [sloc:mystringtokeniser.adb:8]: Mystringtokeniser__tokenextent.__split_fields

end

(* Module giving axioms for type "tokenextent" defined at mystringtokeniser.ads:5, created in Gnat2Why.Types.Generate_Type_Completion *)
module Mystringtokeniser__tokenextent___axiom
  
  use import _gnatprove_standard.Main
  use import int.Int
  use        Mystringtokeniser__tokenextent
  
  function   dynamic_invariant
    (([mlw:proxy_symbol]
    [introduced] temp___expr_167) : Mystringtokeniser__tokenextent.tokenextent
    ([mlw:proxy_symbol] [introduced] temp___is_init_163) : bool
    ([mlw:proxy_symbol] [introduced] temp___skip_constant_164) : bool
    ([mlw:proxy_symbol] [introduced] temp___do_toplevel_165) : bool
    ([mlw:proxy_symbol] [introduced] temp___do_typ_inv_166) : bool) requires
    { True } ensures  { True } returns  = True
  
  function   default_initial_assumption
    (([mlw:proxy_symbol]
    [introduced] temp___expr_168) : Mystringtokeniser__tokenextent.tokenextent
    ([mlw:proxy_symbol] [introduced] temp___skip_top_level_169) : bool)
    requires { True } ensures  { True } returns  = True

end

(* Module for defining a ref holding the value of variable "processed" defined at mystringtokeniser.adb:9, created in Gnat2Why.Decls.Translate_Variable *)
module Mystringtokeniser__tokenise__processed
  
  use import _gnatprove_standard.Main
  use import int.Int
  
  val processed [model_projected] [name:Processed]
  [model_trace:839] [sloc:mystringtokeniser.adb:9]: int

end

(* Module for defining a ref holding the value of variable "outindex" defined at mystringtokeniser.adb:10, created in Gnat2Why.Decls.Translate_Variable *)
module Mystringtokeniser__tokenise__outindex
  
  use import _gnatprove_standard.Main
  use import int.Int
  
  val outindex [name:OutIndex] [model_projected]
  [model_trace:843] [sloc:mystringtokeniser.adb:10]: int

end

(* Module for axiomatizing type "tokenarray" defined at mystringtokeniser.ads:10, created in Gnat2Why.Types.Translate_Type *)
module Mystringtokeniser__tokenarray
  
  use import _gnatprove_standard.Main
  use import int.Int
  use import int.Int
  use        Standard__integer
  use        Standard__positive
  use        Standard__integer__rep
  use        Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  
  type component_type  = --pp_transparent_type_definition NOT IMPLEMENTED
  
  function   index_1_id (x : int) requires { True } ensures  { True } returns
    int = x
  
  clone export ada__model.Unconstr_Array with axiom . type map = Array__Int__Mystringtokeniser__tokenextent.map,
    function array_bool_eq = Array__Int__Mystringtokeniser__tokenextent.bool_eq,
    type index_base_type = Standard__integer.integer,
    type index_rep_type = int,
    function to_rep = Standard__integer__rep.to_rep,
    function rep_to_int = index_1_id,
    predicate in_range_base = Standard__integer.in_range,
    predicate index_dynamic_property = Standard__positive.dynamic_property,
    predicate index_rep_le = <=
  
  type tokenarray  = --pp_transparent_type_definition NOT IMPLEMENTED
  
  meta model_projection function to_array
  
  meta inline:no function to_array
  
  meta model_projection function first
  
  meta inline:no function first
  
  meta model_projection function last
  
  meta inline:no function last
  
  type tokenarray__ref  = { mutable tokenarray__content : tokenarray }
  
  function   tokenarray__ref_tokenarray__content__projection
    (a : tokenarray__ref) requires {  } ensures  {  } returns
    tokenarray = a.tokenarray__content
  
  meta model_projection function tokenarray__ref_tokenarray__content__projection
  
  meta inline:no function tokenarray__ref_tokenarray__content__projection
  
  function   tokenarray__havoc (x : tokenarray__ref) requires {  } ensures 
    {  } returns unit

end

(* Module for axiomatizing type "S2b" defined at mystringtokeniser.adb:6, created in Gnat2Why.Types.Translate_Type *)
module Mystringtokeniser__tokenise__S2b
  
  use export Mystringtokeniser__tokenarray
  use import _gnatprove_standard.Main
  use import int.Int
  
  type s2b  = --pp_transparent_type_definition NOT IMPLEMENTED
  
  type s2b__ref  = { mutable s2b__content : s2b }
  
  function   s2b__ref_s2b__content__projection (a : s2b__ref) requires {  }
    ensures  {  } returns s2b = a.s2b__content
  
  meta model_projection function s2b__ref_s2b__content__projection
  
  meta inline:no function s2b__ref_s2b__content__projection
  
  function   s2b__havoc (x : s2b__ref) requires {  } ensures  {  } returns
    unit

end

(* Module for defining the loop exit exception for the loop "L_1" defined at mystringtokeniser.adb:17, created in Gnat2Why.Decls.Translate_Loop_Entity *)
module Mystringtokeniser__tokenise__L_1
  
  use import _gnatprove_standard.Main
  use import int.Int
  
  --pp_exception_declaration NOT IMPLEMENTED

end

(* Module for defining the loop exit exception for the loop "L_2" defined at mystringtokeniser.adb:45, created in Gnat2Why.Decls.Translate_Loop_Entity *)
module Mystringtokeniser__tokenise__L_2
  
  use import _gnatprove_standard.Main
  use import int.Int
  
  --pp_exception_declaration NOT IMPLEMENTED

end

(* Module for defining the loop exit exception for the loop "L_3" defined at mystringtokeniser.adb:56, created in Gnat2Why.Decls.Translate_Loop_Entity *)
module Mystringtokeniser__tokenise__L_3
  
  use import _gnatprove_standard.Main
  use import int.Int
  
  --pp_exception_declaration NOT IMPLEMENTED

end

(* Module giving an empty axiom for the entity "index" defined at mystringtokeniser.adb:7, created in Gnat2Why.Driver.Translate_Entity.Generate_Empty_Axiom_Theory *)
module Mystringtokeniser__tokenise__index___axiom
  
  use import _gnatprove_standard.Main
  use import int.Int
  
  

end

(* Module giving an empty axiom for the entity "extent" defined at mystringtokeniser.adb:8, created in Gnat2Why.Driver.Translate_Entity.Generate_Empty_Axiom_Theory *)
module Mystringtokeniser__tokenise__extent___axiom
  
  use import _gnatprove_standard.Main
  use import int.Int
  
  

end

(* Module giving an empty axiom for the entity "processed" defined at mystringtokeniser.adb:9, created in Gnat2Why.Driver.Translate_Entity.Generate_Empty_Axiom_Theory *)
module Mystringtokeniser__tokenise__processed___axiom
  
  use import _gnatprove_standard.Main
  use import int.Int
  
  

end

(* Module giving an empty axiom for the entity "outindex" defined at mystringtokeniser.adb:10, created in Gnat2Why.Driver.Translate_Entity.Generate_Empty_Axiom_Theory *)
module Mystringtokeniser__tokenise__outindex___axiom
  
  use import _gnatprove_standard.Main
  use import int.Int
  
  

end

(* Module giving an empty axiom for the entity "L_2" defined at mystringtokeniser.adb:45, created in Gnat2Why.Driver.Translate_Entity.Generate_Empty_Axiom_Theory *)
module Mystringtokeniser__tokenise__L_2___axiom
  
  use import _gnatprove_standard.Main
  use import int.Int
  
  

end

(* Module giving an empty axiom for the entity "L_3" defined at mystringtokeniser.adb:56, created in Gnat2Why.Driver.Translate_Entity.Generate_Empty_Axiom_Theory *)
module Mystringtokeniser__tokenise__L_3___axiom
  
  use import _gnatprove_standard.Main
  use import int.Int
  
  

end

(* Module giving an empty axiom for the entity "L_1" defined at mystringtokeniser.adb:17, created in Gnat2Why.Driver.Translate_Entity.Generate_Empty_Axiom_Theory *)
module Mystringtokeniser__tokenise__L_1___axiom
  
  use import _gnatprove_standard.Main
  use import int.Int
  
  

end

(* Module giving axioms for type "tokenarray" defined at mystringtokeniser.ads:10, created in Gnat2Why.Types.Generate_Type_Completion *)
module Mystringtokeniser__tokenarray___axiom
  
  use import _gnatprove_standard.Main
  use import int.Int
  use        Standard__positive
  use        Mystringtokeniser__tokenarray
  
  function   dynamic_invariant
    (([mlw:proxy_symbol]
    [introduced] temp___expr_176) : Mystringtokeniser__tokenarray.tokenarray
    ([mlw:proxy_symbol] [introduced] temp___is_init_172) : bool
    ([mlw:proxy_symbol] [introduced] temp___skip_constant_173) : bool
    ([mlw:proxy_symbol] [introduced] temp___do_toplevel_174) : bool
    ([mlw:proxy_symbol] [introduced] temp___do_typ_inv_175) : bool) requires
    { True } ensures  { True } returns
     = (if ([mlw:proxy_symbol] [introduced] temp___skip_constant_173) then
       True  else
       (Mystringtokeniser__tokenarray.dynamic_property
          Standard__positive.first Standard__positive.last
          (Mystringtokeniser__tokenarray.first ([mlw:proxy_symbol]
             [introduced] temp___expr_176))
          (Mystringtokeniser__tokenarray.last ([mlw:proxy_symbol]
             [introduced] temp___expr_176))))

end

(* Module giving an empty axiom for the entity "s" defined at mystringtokeniser.ads:16, created in Gnat2Why.Driver.Translate_Entity.Generate_Empty_Axiom_Theory *)
module Mystringtokeniser__tokenise__s___axiom
  
  use import _gnatprove_standard.Main
  use import int.Int
  
  

end

(* Module giving an empty axiom for the entity "tokens" defined at mystringtokeniser.ads:16, created in Gnat2Why.Driver.Translate_Entity.Generate_Empty_Axiom_Theory *)
module Mystringtokeniser__tokenise__tokens___axiom
  
  use import _gnatprove_standard.Main
  use import int.Int
  
  

end

(* Module giving an empty axiom for the entity "count" defined at mystringtokeniser.ads:16, created in Gnat2Why.Driver.Translate_Entity.Generate_Empty_Axiom_Theory *)
module Mystringtokeniser__tokenise__count___axiom
  
  use import _gnatprove_standard.Main
  use import int.Int
  
  

end

(* Module giving axioms for type "S2b" defined at mystringtokeniser.adb:6, created in Gnat2Why.Types.Generate_Type_Completion *)
module Mystringtokeniser__tokenise__S2b___axiom
  
  use import _gnatprove_standard.Main
  use import int.Int
  use        Standard__integer__rep
  use        Mystringtokeniser__tokenise__tokens
  use        Mystringtokeniser__tokenise__S2b
  
  function   dynamic_invariant
    (([mlw:proxy_symbol]
    [introduced] temp___expr_189) : Mystringtokeniser__tokenise__S2b.s2b
    ([mlw:proxy_symbol] [introduced] temp___is_init_185) : bool
    ([mlw:proxy_symbol] [introduced] temp___skip_constant_186) : bool
    ([mlw:proxy_symbol] [introduced] temp___do_toplevel_187) : bool
    ([mlw:proxy_symbol] [introduced] temp___do_typ_inv_188) : bool) requires
    { True } ensures  { True } returns
     = (if ([mlw:proxy_symbol] [introduced] temp___skip_constant_186) then
       True  else
       (((Mystringtokeniser__tokenise__S2b.dynamic_property
            (Standard__integer__rep.to_rep
               Mystringtokeniser__tokenise__tokens.tokens__first)
            (Standard__integer__rep.to_rep
               Mystringtokeniser__tokenise__tokens.tokens__last)
            (Mystringtokeniser__tokenise__S2b.first ([mlw:proxy_symbol]
               [introduced] temp___expr_189))
            (Mystringtokeniser__tokenise__S2b.last ([mlw:proxy_symbol]
               [introduced] temp___expr_189))) /\
           ((Mystringtokeniser__tokenise__S2b.first ([mlw:proxy_symbol]
               [introduced] temp___expr_189))
              = (Standard__integer__rep.to_rep
                   Mystringtokeniser__tokenise__tokens.tokens__first))) /\
          ((Mystringtokeniser__tokenise__S2b.last ([mlw:proxy_symbol]
              [introduced] temp___expr_189))
             = (Standard__integer__rep.to_rep
                  Mystringtokeniser__tokenise__tokens.tokens__last))))
  
  function   default_initial_assumption
    (([mlw:proxy_symbol]
    [introduced] temp___expr_191) : Mystringtokeniser__tokenise__S2b.s2b
    ([mlw:proxy_symbol] [introduced] temp___skip_top_level_192) : bool)
    requires { True } ensures  { True } returns
     = (True /\
          ((Mystringtokeniser__tokenise__S2b.first ([mlw:proxy_symbol]
              [introduced] temp___expr_191))
             = (Standard__integer__rep.to_rep
                  Mystringtokeniser__tokenise__tokens.tokens__first)) /\
          ((Mystringtokeniser__tokenise__S2b.last ([mlw:proxy_symbol]
              [introduced] temp___expr_191))
             = (Standard__integer__rep.to_rep
                  Mystringtokeniser__tokenise__tokens.tokens__last)))

end

(* Module for checking contracts and absence of run-time errors in subprogram "tokenise" defined at mystringtokeniser.ads:16, created in Gnat2Why.Subprograms.Generate_VCs_For_Subprogram *)
module Mystringtokeniser__tokenise__subprogram_def
  
  use import _gnatprove_standard.Main
  use import int.Int
  use import int.Int
  use        _gnatprove_standard.Main
  use        _gnatprove_standard.Integer
  use        _gnatprove_standard.Boolean
  use        Standard__integer
  use        Standard__integer___axiom
  use        Standard__natural
  use        Standard__natural___axiom
  use        Standard__natural__rep
  use        Standard__positive
  use        Standard__positive___axiom
  use        Standard__positive__rep
  use        Standard__character
  use        Standard__character__rep
  use        Array__Int__Standard__character
  use        Standard__string
  use        Standard__integer__rep
  use        Standard__string___axiom
  use        Mystringtokeniser__is_whitespace
  use        Mystringtokeniser__is_whitespace___axiom
  use        Mystringtokeniser__tokenise__s
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Mystringtokeniser__tokenise__tokens
  use        Mystringtokeniser__tokenise__count
  use        Mystringtokeniser__tokenise__index
  use        Mystringtokeniser__tokenise__extent
  use        Mystringtokeniser__tokenextent
  use        Mystringtokeniser__tokenextent___axiom
  use        Mystringtokeniser__tokenise__processed
  use        Mystringtokeniser__tokenise__outindex
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Mystringtokeniser__tokenarray
  use        Mystringtokeniser__tokenise__S2b
  use        Mystringtokeniser__tokenise__L_1
  use        Mystringtokeniser__tokenise__L_2
  use        Mystringtokeniser__tokenise__L_3
  use        Array__Int__Standard__character
  use        Array__Int__Standard__character
  use        Array__Int__Standard__character
  use        Array__Int__Standard__character
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Standard__character
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Array__Int__Mystringtokeniser__tokenextent
  use        Standard__integer___axiom
  use        Standard__natural___axiom
  use        Standard__positive___axiom
  use        Standard__character___axiom
  use        Standard__string___axiom
  use        Standard__integer___axiom
  use        Mystringtokeniser__tokenise__index___axiom
  use        Mystringtokeniser__tokenise__extent___axiom
  use        Mystringtokeniser__tokenise__processed___axiom
  use        Mystringtokeniser__tokenise__outindex___axiom
  use        Mystringtokeniser__tokenise__L_2___axiom
  use        Mystringtokeniser__tokenise__L_3___axiom
  use        Mystringtokeniser__tokenise__L_1___axiom
  use        Mystringtokeniser__tokenextent___axiom
  use        Mystringtokeniser__tokenarray___axiom
  use        Mystringtokeniser__is_whitespace___axiom
  use        Mystringtokeniser__tokenise__s___axiom
  use        Mystringtokeniser__tokenise__tokens___axiom
  use        Mystringtokeniser__tokenise__count___axiom
  use        Mystringtokeniser__tokenise__S2b___axiom
  
  --pp_exception_declaration NOT IMPLEMENTED
  
  function [GP_Subp:mystringtokeniser.ads:16] [sloc:mystringtokeniser.ads:16]
    def (__void_param : unit) requires { True } ensures 
    { ([sloc:mystringtokeniser.ads:18] ([GP_Reason:VC_POSTCONDITION]
                                       [GP_Sloc:mystringtokeniser.ads:18:14]
                                       [GP_Id:31] [model_vc_post]
                                       [comment:     Post => Count <= Tokens'Length and                                  --Line 1              ^ mystringtokeniser.ads:18:14:VC_POSTCONDITION]
                                       [GP_Shape:pragargs__and] (([GP_Pretty_Ada:1208]
                                                                 [GP_Sloc:mystringtokeniser.ads:18:14] (
                                                                 !Mystringtokeniser__tokenise__count.count
                                                                   <= (
                                                                   _gnatprove_standard.Integer.length
                                                                    (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__first)
                                                                    (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__last))))
                                                                   /\
                                                                   --pp_universal_quantif NOT IMPLEMENTED))) }
    returns
     = (* Assume dynamic invariants of inputs of the subprogram mystringtokeniser.ads:16 *);
        assume
        { (Standard__string___axiom.dynamic_invariant
             Mystringtokeniser__tokenise__s.s True False True True) };
        assume
        { ((if False then True  else
           (Mystringtokeniser__tokenarray.dynamic_property
              Standard__positive.first Standard__positive.last
              (Mystringtokeniser__tokenise__S2b.first
                 (Mystringtokeniser__tokenise__S2b.of_array
                    !Mystringtokeniser__tokenise__tokens.tokens
                    (Standard__integer__rep.to_rep
                       Mystringtokeniser__tokenise__tokens.tokens__first)
                    (Standard__integer__rep.to_rep
                       Mystringtokeniser__tokenise__tokens.tokens__last)))
              (Mystringtokeniser__tokenise__S2b.last
                 (Mystringtokeniser__tokenise__S2b.of_array
                    !Mystringtokeniser__tokenise__tokens.tokens
                    (Standard__integer__rep.to_rep
                       Mystringtokeniser__tokenise__tokens.tokens__first)
                    (Standard__integer__rep.to_rep
                       Mystringtokeniser__tokenise__tokens.tokens__last)))))
             /\ --pp_universal_quantif NOT IMPLEMENTED) };
        assume
        { (Standard__natural___axiom.dynamic_invariant
             !Mystringtokeniser__tokenise__count.count False False True True) };
        (* Assume moved pointers in outputs of the subprogram mystringtokeniser.ads:16 *);
        (* Check for RTE in the Pre of the subprogram mystringtokeniser.ads:16 *);
        abstract ensures
        { True } begin  (let _ =
                       (_gnatprove_standard.Boolean.andb
                          (if
                          (abstract ensures
                             { True } begin  (let _ =
                                            Mystringtokeniser__tokenise__s.s
                                            in ())  end;
                             (Standard__string.length
                                Mystringtokeniser__tokenise__s.s) > 0)
                          then
                          (abstract ensures
                             { True } begin  (let _ =
                                            Mystringtokeniser__tokenise__s.s
                                            in ())  end;
                             (Standard__string.first
                                Mystringtokeniser__tokenise__s.s) <= abstract
                             ensures
                             { True } begin  (let _ =
                                            Mystringtokeniser__tokenise__s.s
                                            in ())  end;
                             (Standard__string.last
                                Mystringtokeniser__tokenise__s.s))
                           else (_gnatprove_standard.Boolean.of_int 1))
                          ((Standard__integer__rep.to_rep abstract ensures
                              { True } begin  (let _ =
                                             (Mystringtokeniser__tokenise__S2b.of_array
                                                !Mystringtokeniser__tokenise__tokens.tokens
                                                (Standard__integer__rep.to_rep
                                                   Mystringtokeniser__tokenise__tokens.tokens__first)
                                                (Standard__integer__rep.to_rep
                                                   Mystringtokeniser__tokenise__tokens.tokens__last))
                                             in ())  end;
                              Mystringtokeniser__tokenise__tokens.tokens__first)
                             <= (Standard__integer__rep.to_rep abstract
                                   ensures
                                   { True } begin  (let _ =
                                                  (Mystringtokeniser__tokenise__S2b.of_array
                                                     !Mystringtokeniser__tokenise__tokens.tokens
                                                     (Standard__integer__rep.to_rep
                                                        Mystringtokeniser__tokenise__tokens.tokens__first)
                                                     (Standard__integer__rep.to_rep
                                                        Mystringtokeniser__tokenise__tokens.tokens__last))
                                                  in ())  end;
                                   Mystringtokeniser__tokenise__tokens.tokens__last)))
                       in ())  end;
        (* Assume Pre of the subprogram mystringtokeniser.ads:16 *);
        assume
        { ((if
           ((Standard__string.length Mystringtokeniser__tokenise__s.s) > 0)
           then
           ([GP_Pretty_Ada:1191] ((Standard__string.first
                                     Mystringtokeniser__tokenise__s.s)
                                    <= (Standard__string.last
                                          Mystringtokeniser__tokenise__s.s)))
            else ([GP_Pretty_Ada:3149] True)) /\
             ([GP_Pretty_Ada:1200] ((Standard__integer__rep.to_rep
                                       Mystringtokeniser__tokenise__tokens.tokens__first)
                                      <= (Standard__integer__rep.to_rep
                                            Mystringtokeniser__tokenise__tokens.tokens__last)))) };
        (try
        ();
          ([sloc:mystringtokeniser.adb:6] ());
          ([sloc:mystringtokeniser.adb:6] ());
          ([sloc:mystringtokeniser.adb:7] assume
          { (Standard__positive___axiom.default_initial_assumption
               !Mystringtokeniser__tokenise__index.index False) };
          assume
          { (Standard__positive___axiom.dynamic_invariant
               !Mystringtokeniser__tokenise__index.index False False True
               True) });
          ([sloc:mystringtokeniser.adb:8] abstract ensures
          { True } begin  (let _ =
                         (let ([mlw:proxy_symbol] [introduced] temp___208) =
                           ( any  pre {} post {True} return
                             Mystringtokeniser__tokenextent.tokenextent)
                         in ())
          in ())  end;
          assume
          { (Mystringtokeniser__tokenextent___axiom.default_initial_assumption
               --pp_record_aggregate NOT IMPLEMENTED False) };
          assume
          { (Mystringtokeniser__tokenextent___axiom.dynamic_invariant
               --pp_record_aggregate NOT IMPLEMENTED False False True True) });
        ([sloc:mystringtokeniser.adb:9] (
        Mystringtokeniser__tokenise__processed.processed := ( 0));
        assume
        { (Standard__natural___axiom.dynamic_invariant
             !Mystringtokeniser__tokenise__processed.processed True False
             True True) });
        ([sloc:mystringtokeniser.adb:10] (
        Mystringtokeniser__tokenise__outindex.outindex :=
        ( (Standard__integer__rep.to_rep abstract ensures
             { True } begin  (let _ =
                            (Mystringtokeniser__tokenise__S2b.of_array
                               !Mystringtokeniser__tokenise__tokens.tokens
                               (Standard__integer__rep.to_rep
                                  Mystringtokeniser__tokenise__tokens.tokens__first)
                               (Standard__integer__rep.to_rep
                                  Mystringtokeniser__tokenise__tokens.tokens__last))
                            in ())  end;
             Mystringtokeniser__tokenise__tokens.tokens__first)));
        assume
        { (Standard__integer___axiom.dynamic_invariant
             !Mystringtokeniser__tokenise__outindex.outindex True False True
             True) });
        ([sloc:mystringtokeniser.adb:45] ());
        ([sloc:mystringtokeniser.adb:56] ());
        ([sloc:mystringtokeniser.adb:17] ());
        ();
        ([GP_Sloc:mystringtokeniser.adb:12:13] ([sloc:mystringtokeniser.adb:12] (
                                               Mystringtokeniser__tokenise__count.count
                                               := ( 0))));
        ([GP_Sloc:mystringtokeniser.adb:13:7] ([sloc:mystringtokeniser.adb:13] 
                                              (if
                                              ([sloc:mystringtokeniser.adb:13] ([branch_id=853]
                                              _gnatprove_standard.Main.spark__branch
                                              :=
                                              (abstract ensures
                                                 { True } begin  (let _ =
                                                                Mystringtokeniser__tokenise__s.s
                                                                in ())  end;
                                                 (Standard__string.first
                                                    Mystringtokeniser__tokenise__s.s)
                                                 > abstract ensures
                                                 { True } begin  (let _ =
                                                                Mystringtokeniser__tokenise__s.s
                                                                in ())  end;
                                                 (Standard__string.last
                                                    Mystringtokeniser__tokenise__s.s))));
                                              ([branch_id=853] _gnatprove_standard.Main.spark__branch).bool__content
                                              then
                                              ();
                                              ([GP_Sloc:mystringtokeniser.adb:14:10] 
                                              ([sloc:mystringtokeniser.adb:14] raise Return__exc))
                                               else ())));
        ([GP_Sloc:mystringtokeniser.adb:16:7] ([sloc:mystringtokeniser.adb:16] ()));
        ([GP_Sloc:mystringtokeniser.adb:16:13] ([sloc:mystringtokeniser.adb:16] (
                                               Mystringtokeniser__tokenise__index.index
                                               :=
                                               ( ([sloc:mystringtokeniser.adb:16] 
                                                 ([vc:annotation]
                                                 [GP_Shape:index_assign__first_ref]
                                                 [GP_Reason:VC_RANGE_CHECK]
                                                 [GP_Id:0]
                                                 [comment:      Index := S'First;                 ^ mystringtokeniser.adb:16:17:VC_RANGE_CHECK]
                                                 [GP_Sloc:mystringtokeniser.adb:16:17] (
                                                 Standard__positive.range_check_
                                                   abstract ensures
                                                   { True } begin  (let _ =
                                                                  Mystringtokeniser__tokenise__s.s
                                                                  in ())  end;
                                                   (Standard__string.first
                                                      Mystringtokeniser__tokenise__s.s))))))));
        ([GP_Sloc:mystringtokeniser.adb:17:87] ([sloc:mystringtokeniser.adb:17] 
                                               (* Translation of an Ada loop from mystringtokeniser.adb:17 *);
                                               (if
                                               (_gnatprove_standard.Boolean.andb
                                                  (_gnatprove_standard.Boolean.andb
                                                     (!Mystringtokeniser__tokenise__outindex.outindex
                                                        <= (Standard__integer__rep.to_rep
                                                              abstract
                                                              ensures
                                                              { True } begin 
                                                               (let _ =
                                                              (Mystringtokeniser__tokenise__S2b.of_array
                                                                 !Mystringtokeniser__tokenise__tokens.tokens
                                                                 (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__first)
                                                                 (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__last))
                                                              in ())  end;
                                                              Mystringtokeniser__tokenise__tokens.tokens__last))
                                                     (!Mystringtokeniser__tokenise__index.index
                                                        <= abstract ensures
                                                        { True } begin 
                                                         (let _ =
                                                        Mystringtokeniser__tokenise__s.s
                                                        in ())  end;
                                                        (Standard__string.last
                                                           Mystringtokeniser__tokenise__s.s)))
                                                  (!Mystringtokeniser__tokenise__processed.processed
                                                     < ([sloc:mystringtokeniser.adb:17] 
                                                       ([GP_Shape:L_1_while__and__cmp__typeconv__length_ref]
                                                       [vc:annotation]
                                                       [GP_Reason:VC_RANGE_CHECK]
                                                       [GP_Sloc:mystringtokeniser.adb:17:79]
                                                       [comment:      while OutIndex <= Tokens'Last and Index <= S'Last and Processed < Tokens'Length loop                                                                               ^ mystringtokeniser.adb:17:79:VC_RANGE_CHECK]
                                                       [GP_Id:23] (Standard__integer.range_check_
                                                                    abstract
                                                                    ensures
                                                                    { True } begin 
                                                                     (let _ =
                                                                    (Mystringtokeniser__tokenise__S2b.of_array
                                                                    !Mystringtokeniser__tokenise__tokens.tokens
                                                                    (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__first)
                                                                    (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__last))
                                                                    in ())  end;
                                                                    (_gnatprove_standard.Integer.length
                                                                    (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__first)
                                                                    (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__last)))))))
                                               then
                                               (try
                                               (try
                                                 (let temp___loop_entry_236 =
                                                   --pp_record_aggregate NOT IMPLEMENTED
                                                   in
                                                   (let temp___loop_entry_234
                                                   =
                                                   (Mystringtokeniser__tokenise__S2b.of_array
                                                      !Mystringtokeniser__tokenise__tokens.tokens
                                                      (Standard__integer__rep.to_rep
                                                         Mystringtokeniser__tokenise__tokens.tokens__first)
                                                      (Standard__integer__rep.to_rep
                                                         Mystringtokeniser__tokenise__tokens.tokens__last))
                                                   in
                                                   (* While loop translating the Ada loop from mystringtokeniser.adb:17 *);
                                                   ([sloc:mystringtokeniser.adb:30] 
                                                   loop
                                                     (* Check for absence of RTE in the loop invariant and variant *);
                                                     (let ([mlw:proxy_symbol]
                                                     [introduced] temp___inv_238)
                                                     =
                                                     (let j =
                                                       ( any  pre {} post {
                                                         } return int) in
                                                     (if
                                                     (_gnatprove_standard.Boolean.andb
                                                        ((Standard__integer__rep.to_rep
                                                            abstract ensures
                                                            { True } begin 
                                                             (let _ =
                                                            (Mystringtokeniser__tokenise__S2b.of_array
                                                               !Mystringtokeniser__tokenise__tokens.tokens
                                                               (Standard__integer__rep.to_rep
                                                                  Mystringtokeniser__tokenise__tokens.tokens__first)
                                                               (Standard__integer__rep.to_rep
                                                                  Mystringtokeniser__tokenise__tokens.tokens__last))
                                                            in ())  end;
                                                            Mystringtokeniser__tokenise__tokens.tokens__first)
                                                           <= j)
                                                        (j
                                                           <= ([sloc:mystringtokeniser.adb:19] 
                                                              ([GP_Id:16]
                                                              [GP_Sloc:mystringtokeniser.adb:19:48]
                                                              [vc:annotation]
                                                              [GP_Reason:VC_OVERFLOW_CHECK]
                                                              [GP_Shape:L_1_while__pragargs__forall__range__sub]
                                                              [comment:           (for all J in Tokens'First..OutIndex-1 =>                                                ^ mystringtokeniser.adb:19:48:VC_OVERFLOW_CHECK] (
                                                              Standard__integer.range_check_
                                                                (!Mystringtokeniser__tokenise__outindex.outindex
                                                                   - 1))))))
                                                     then
                                                     abstract ensures
                                                     { True } begin  (let _ =
                                                                    ((_gnatprove_standard.Boolean.andb
                                                                    ((Standard__positive__rep.to_rep
                                                                    ( (let ([mlw:proxy_symbol]
                                                                    [introduced] temp___239)
                                                                    =
                                                                    (Mystringtokeniser__tokenise__S2b.of_array
                                                                    !Mystringtokeniser__tokenise__tokens.tokens
                                                                    (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__first)
                                                                    (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__last))
                                                                    in
                                                                    (
                                                                    Array__Int__Mystringtokeniser__tokenextent.get
                                                                    (Mystringtokeniser__tokenise__S2b.to_array
                                                                    ([mlw:proxy_symbol]
                                                                    [introduced] temp___239))
                                                                    assert
                                                                    { ([sloc:mystringtokeniser.adb:20] 
                                                                    ([GP_Id:17]
                                                                    [GP_Sloc:mystringtokeniser.adb:20:23]
                                                                    [vc:annotation]
                                                                    [GP_Shape:L_1_while__pragargs__forall__andthen__and__cmp__selectcomp__ixdcomp]
                                                                    [GP_Reason:VC_INDEX_CHECK]
                                                                    [comment:              (Tokens(J).Start >= S'First and                       ^ mystringtokeniser.adb:20:23:VC_INDEX_CHECK] (
                                                                    ((Mystringtokeniser__tokenise__S2b.first
                                                                    ([mlw:proxy_symbol]
                                                                    [introduced] temp___239))
                                                                    <= j) /\
                                                                    (j
                                                                    <= (
                                                                    Mystringtokeniser__tokenise__S2b.last
                                                                    ([mlw:proxy_symbol]
                                                                    [introduced] temp___239)))))) };
                                                                    j))).Mystringtokeniser__tokenextent.__split_fields.Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start)
                                                                    >= abstract
                                                                    ensures
                                                                    { True } begin 
                                                                     (let _ =
                                                                    Mystringtokeniser__tokenise__s.s
                                                                    in ())  end;
                                                                    (Standard__string.first
                                                                    Mystringtokeniser__tokenise__s.s))
                                                                    ((Standard__natural__rep.to_rep
                                                                    ( (let ([mlw:proxy_symbol]
                                                                    [introduced] temp___240)
                                                                    =
                                                                    (Mystringtokeniser__tokenise__S2b.of_array
                                                                    !Mystringtokeniser__tokenise__tokens.tokens
                                                                    (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__first)
                                                                    (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__last))
                                                                    in
                                                                    (
                                                                    Array__Int__Mystringtokeniser__tokenextent.get
                                                                    (Mystringtokeniser__tokenise__S2b.to_array
                                                                    ([mlw:proxy_symbol]
                                                                    [introduced] temp___240))
                                                                    assert
                                                                    { ([sloc:mystringtokeniser.adb:21] 
                                                                    ([GP_Id:18]
                                                                    [comment:                   Tokens(J).Length > 0) and then                           ^ mystringtokeniser.adb:21:27:VC_INDEX_CHECK]
                                                                    [vc:annotation]
                                                                    [GP_Shape:L_1_while__pragargs__forall__andthen__and__cmp__selectcomp__ixdcomp]
                                                                    [GP_Sloc:mystringtokeniser.adb:21:27]
                                                                    [GP_Reason:VC_INDEX_CHECK] (
                                                                    ((Mystringtokeniser__tokenise__S2b.first
                                                                    ([mlw:proxy_symbol]
                                                                    [introduced] temp___240))
                                                                    <= j) /\
                                                                    (j
                                                                    <= (
                                                                    Mystringtokeniser__tokenise__S2b.last
                                                                    ([mlw:proxy_symbol]
                                                                    [introduced] temp___240)))))) };
                                                                    j))).Mystringtokeniser__tokenextent.__split_fields.Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length)
                                                                    > 0)) &&
                                                                    (((Standard__natural__rep.to_rep
                                                                    ( (let ([mlw:proxy_symbol]
                                                                    [introduced] temp___241)
                                                                    =
                                                                    (Mystringtokeniser__tokenise__S2b.of_array
                                                                    !Mystringtokeniser__tokenise__tokens.tokens
                                                                    (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__first)
                                                                    (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__last))
                                                                    in
                                                                    (
                                                                    Array__Int__Mystringtokeniser__tokenextent.get
                                                                    (Mystringtokeniser__tokenise__S2b.to_array
                                                                    ([mlw:proxy_symbol]
                                                                    [introduced] temp___241))
                                                                    assert
                                                                    { ([sloc:mystringtokeniser.adb:22] 
                                                                    ([GP_Id:19]
                                                                    [vc:annotation]
                                                                    [comment:            Tokens(J).Length-1 <= S'Last - Tokens(J).Start);                    ^ mystringtokeniser.adb:22:20:VC_INDEX_CHECK]
                                                                    [GP_Reason:VC_INDEX_CHECK]
                                                                    [GP_Sloc:mystringtokeniser.adb:22:20]
                                                                    [GP_Shape:L_1_while__pragargs__forall__andthen__cmp__sub__selectcomp__ixdcomp] (
                                                                    ((Mystringtokeniser__tokenise__S2b.first
                                                                    ([mlw:proxy_symbol]
                                                                    [introduced] temp___241))
                                                                    <= j) /\
                                                                    (j
                                                                    <= (
                                                                    Mystringtokeniser__tokenise__S2b.last
                                                                    ([mlw:proxy_symbol]
                                                                    [introduced] temp___241)))))) };
                                                                    j))).Mystringtokeniser__tokenextent.__split_fields.Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length)
                                                                    - 1)
                                                                    <= ([sloc:mystringtokeniser.adb:22] 
                                                                    ([vc:annotation]
                                                                    [GP_Sloc:mystringtokeniser.adb:22:42]
                                                                    [GP_Reason:VC_OVERFLOW_CHECK]
                                                                    [comment:            Tokens(J).Length-1 <= S'Last - Tokens(J).Start);                                          ^ mystringtokeniser.adb:22:42:VC_OVERFLOW_CHECK]
                                                                    [GP_Shape:L_1_while__pragargs__forall__andthen__cmp__sub]
                                                                    [GP_Id:21] (
                                                                    Standard__integer.range_check_
                                                                    (abstract
                                                                    ensures
                                                                    { True } begin 
                                                                     (let _ =
                                                                    Mystringtokeniser__tokenise__s.s
                                                                    in ())  end;
                                                                    (Standard__string.last
                                                                    Mystringtokeniser__tokenise__s.s)
                                                                    - (Standard__positive__rep.to_rep
                                                                    ( (let ([mlw:proxy_symbol]
                                                                    [introduced] temp___242)
                                                                    =
                                                                    (Mystringtokeniser__tokenise__S2b.of_array
                                                                    !Mystringtokeniser__tokenise__tokens.tokens
                                                                    (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__first)
                                                                    (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__last))
                                                                    in
                                                                    (
                                                                    Array__Int__Mystringtokeniser__tokenextent.get
                                                                    (Mystringtokeniser__tokenise__S2b.to_array
                                                                    ([mlw:proxy_symbol]
                                                                    [introduced] temp___242))
                                                                    assert
                                                                    { ([sloc:mystringtokeniser.adb:22] 
                                                                    ([GP_Sloc:mystringtokeniser.adb:22:51]
                                                                    [comment:            Tokens(J).Length-1 <= S'Last - Tokens(J).Start);                                                   ^ mystringtokeniser.adb:22:51:VC_INDEX_CHECK]
                                                                    [vc:annotation]
                                                                    [GP_Reason:VC_INDEX_CHECK]
                                                                    [GP_Id:20]
                                                                    [GP_Shape:L_1_while__pragargs__forall__andthen__cmp__sub__selectcomp__ixdcomp] (
                                                                    ((Mystringtokeniser__tokenise__S2b.first
                                                                    ([mlw:proxy_symbol]
                                                                    [introduced] temp___242))
                                                                    <= j) /\
                                                                    (j
                                                                    <= (
                                                                    Mystringtokeniser__tokenise__S2b.last
                                                                    ([mlw:proxy_symbol]
                                                                    [introduced] temp___242)))))) };
                                                                    j))).Mystringtokeniser__tokenextent.__split_fields.Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start)))))))
                                                                    in ())  end
                                                     ));
                                                     ( any  pre {} post
                                                     {((result = True) <->
                                                         --pp_universal_quantif NOT IMPLEMENTED)}
                                                     return bool) in abstract
                                                   ensures
                                                   { True } begin  (let _ =
                                                                  (let ([mlw:proxy_symbol]
                                                                    [introduced] temp___inv_237)
                                                                    =
                                                                    (!Mystringtokeniser__tokenise__outindex.outindex
                                                                    = ([sloc:mystringtokeniser.adb:30] 
                                                                    ([GP_Id:14]
                                                                    [GP_Shape:L_1_while__pragargs__cmp__add]
                                                                    [vc:annotation]
                                                                    [GP_Reason:VC_OVERFLOW_CHECK]
                                                                    [GP_Sloc:mystringtokeniser.adb:30:57]
                                                                    [comment:         pragma Loop_Invariant (OutIndex = Tokens'First + Processed);                                                         ^ mystringtokeniser.adb:30:57:VC_OVERFLOW_CHECK] (
                                                                    Standard__integer.range_check_
                                                                    ((Standard__integer__rep.to_rep
                                                                    abstract
                                                                    ensures
                                                                    { True } begin 
                                                                     (let _ =
                                                                    (Mystringtokeniser__tokenise__S2b.of_array
                                                                    !Mystringtokeniser__tokenise__tokens.tokens
                                                                    (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__first)
                                                                    (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__last))
                                                                    in ())  end;
                                                                    Mystringtokeniser__tokenise__tokens.tokens__first)
                                                                    + !Mystringtokeniser__tokenise__processed.processed)))))
                                                                    in
                                                                    abstract
                                                                    ensures
                                                                    { True } begin 
                                                                     (let _ =
                                                                    () in
                                                                    ())  end)
                                                                  in ())  end)
                                                   invariant
                                                   {([sloc:mystringtokeniser.adb:19] 
                                                    ([GP_Reason:VC_LOOP_INVARIANT]
                                                    [vc:annotation]
                                                    [comment:           (for all J in Tokens'First..OutIndex-1 =>             ^ mystringtokeniser.adb:19:13:VC_LOOP_INVARIANT]
                                                    [GP_Shape:L_1_while__pragargs__forall]
                                                    [GP_Id:22]
                                                    [GP_Sloc:mystringtokeniser.adb:19:13] --pp_universal_quantif NOT IMPLEMENTED))}
                                                   invariant
                                                   {([sloc:mystringtokeniser.adb:30] 
                                                    ([GP_Reason:VC_LOOP_INVARIANT]
                                                    [GP_Id:15]
                                                    [vc:annotation]
                                                    [GP_Shape:L_1_while__pragargs__cmp]
                                                    [comment:         pragma Loop_Invariant (OutIndex = Tokens'First + Processed);                                 ^ mystringtokeniser.adb:30:33:VC_LOOP_INVARIANT]
                                                    [GP_Sloc:mystringtokeniser.adb:30:33] 
                                                    ([GP_Pretty_Ada:940]
                                                    [GP_Sloc:mystringtokeniser.adb:30:33] (
                                                    !Mystringtokeniser__tokenise__outindex.outindex
                                                      = ((Standard__integer__rep.to_rep
                                                            Mystringtokeniser__tokenise__tokens.tokens__first)
                                                           + !Mystringtokeniser__tokenise__processed.processed)))))}
                                                   
                                                   (* Assume implicit invariants from the loop mystringtokeniser.adb:17 *);
                                                   assume
                                                   { (_gnatprove_standard.Boolean.andb
                                                        ((((((True /\
                                                                --pp_universal_quantif NOT IMPLEMENTED
                                                                /\ True /\
                                                                True) /\
                                                               (Standard__natural___axiom.dynamic_invariant
                                                                  !Mystringtokeniser__tokenise__count.count
                                                                  False True
                                                                  True True)
                                                               /\ True /\
                                                               True) /\
                                                              (Standard__positive___axiom.dynamic_invariant
                                                                 !Mystringtokeniser__tokenise__index.index
                                                                 False True
                                                                 True True)
                                                              /\ True /\ True)
                                                             /\
                                                             (Mystringtokeniser__tokenextent___axiom.dynamic_invariant
                                                                --pp_record_aggregate NOT IMPLEMENTED
                                                                False True
                                                                True True) /\
                                                             True /\ True) /\
                                                            (Standard__natural___axiom.dynamic_invariant
                                                               !Mystringtokeniser__tokenise__processed.processed
                                                               True True True
                                                               True) /\ True
                                                            /\ True) /\
                                                           (Standard__integer___axiom.dynamic_invariant
                                                              !Mystringtokeniser__tokenise__outindex.outindex
                                                              True True True
                                                              True) /\ True
                                                           /\ True)
                                                        (((!Mystringtokeniser__tokenise__outindex.outindex
                                                             <= (Standard__integer__rep.to_rep
                                                                   Mystringtokeniser__tokenise__tokens.tokens__last))
                                                            /\
                                                            (!Mystringtokeniser__tokenise__index.index
                                                               <= (Standard__string.last
                                                                    Mystringtokeniser__tokenise__s.s)))
                                                           /\
                                                           (!Mystringtokeniser__tokenise__processed.processed
                                                              < (_gnatprove_standard.Integer.length
                                                                   (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__first)
                                                                   (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__last))))) };
                                                   (* Continuation of loop after loop invariant and variant *);
                                                   ();
                                                   ([GP_Sloc:mystringtokeniser.adb:45:87] 
                                                   ([sloc:mystringtokeniser.adb:45] 
                                                   (* Translation of an Ada loop from mystringtokeniser.adb:45 *);
                                                   (if
                                                   ((_gnatprove_standard.Boolean.andb
                                                       (!Mystringtokeniser__tokenise__index.index
                                                          >= abstract ensures
                                                          { True } begin 
                                                           (let _ =
                                                          Mystringtokeniser__tokenise__s.s
                                                          in ())  end;
                                                          (Standard__string.first
                                                             Mystringtokeniser__tokenise__s.s))
                                                       (!Mystringtokeniser__tokenise__index.index
                                                          < abstract ensures
                                                          { True } begin 
                                                           (let _ =
                                                          Mystringtokeniser__tokenise__s.s
                                                          in ())  end;
                                                          (Standard__string.last
                                                             Mystringtokeniser__tokenise__s.s)))
                                                      &&
                                                      (Mystringtokeniser__is_whitespace___axiom.is_whitespace
                                                         ( (Standard__character__rep.to_rep
                                                              (Array__Int__Standard__character.get
                                                                 (Standard__string.to_array
                                                                    Mystringtokeniser__tokenise__s.s)
                                                                 assert
                                                                 { ([sloc:mystringtokeniser.adb:45] 
                                                                   ([vc:annotation]
                                                                   [GP_Shape:L_1_while__L_2_while__andthen__call_is_whitespace__ixdcomp]
                                                                   [GP_Reason:VC_INDEX_CHECK]
                                                                   [GP_Id:2]
                                                                   [GP_Sloc:mystringtokeniser.adb:45:79]
                                                                   [comment:         while (Index >= S'First and Index < S'Last) and then Is_Whitespace(S(Index)) loop                                                                               ^ mystringtokeniser.adb:45:79:VC_INDEX_CHECK] (
                                                                   ((Standard__string.first
                                                                    Mystringtokeniser__tokenise__s.s)
                                                                    <= !Mystringtokeniser__tokenise__index.index)
                                                                    /\
                                                                    (!Mystringtokeniser__tokenise__index.index
                                                                    <= (
                                                                    Standard__string.last
                                                                    Mystringtokeniser__tokenise__s.s))))) };
                                                                 !Mystringtokeniser__tokenise__index.index)))))
                                                   then
                                                   (try
                                                   (* While loop translating the Ada loop from mystringtokeniser.adb:45 *);
                                                     ([sloc:mystringtokeniser.adb:45] 
                                                     loop
                                                       (* Check for absence of RTE in the loop invariant and variant *)
                                                       
                                                       
                                                       (* Assume implicit invariants from the loop mystringtokeniser.adb:45 *);
                                                       assume
                                                       { (_gnatprove_standard.Boolean.andb
                                                            (True /\
                                                               (Standard__positive___axiom.dynamic_invariant
                                                                  !Mystringtokeniser__tokenise__index.index
                                                                  False True
                                                                  True True)
                                                               /\ True /\
                                                               True)
                                                            (((!Mystringtokeniser__tokenise__index.index
                                                                 >= (
                                                                 Standard__string.first
                                                                   Mystringtokeniser__tokenise__s.s))
                                                                /\
                                                                (!Mystringtokeniser__tokenise__index.index
                                                                   < (
                                                                   Standard__string.last
                                                                    Mystringtokeniser__tokenise__s.s)))
                                                               /\
                                                               ((epsilon ([mlw:proxy_symbol]
                                                                [introduced] temp___result_213) : bool {
                                                                ((([mlw:proxy_symbol]
                                                                    [introduced] temp___result_213)
                                                                    = (
                                                                    Mystringtokeniser__is_whitespace.is_whitespace
                                                                    ( (
                                                                    Standard__character__rep.to_rep
                                                                    (Array__Int__Standard__character.get
                                                                    (Standard__string.to_array
                                                                    Mystringtokeniser__tokenise__s.s)
                                                                    !Mystringtokeniser__tokenise__index.index)))))
                                                                   /\
                                                                   (Mystringtokeniser__is_whitespace.is_whitespace__function_guard
                                                                    ([mlw:proxy_symbol]
                                                                    [introduced] temp___result_213)
                                                                    ( (
                                                                    Standard__character__rep.to_rep
                                                                    (Array__Int__Standard__character.get
                                                                    (Standard__string.to_array
                                                                    Mystringtokeniser__tokenise__s.s)
                                                                    !Mystringtokeniser__tokenise__index.index)))))})
                                                                  = True))) };
                                                       (* Continuation of loop after loop invariant and variant *);
                                                       ();
                                                       ([GP_Sloc:mystringtokeniser.adb:46:13] 
                                                       ([sloc:mystringtokeniser.adb:46] ()));
                                                       ([GP_Sloc:mystringtokeniser.adb:46:22] 
                                                       ([sloc:mystringtokeniser.adb:46] ()));
                                                       ([GP_Sloc:mystringtokeniser.adb:46:19] 
                                                       ([sloc:mystringtokeniser.adb:46] (
                                                       Mystringtokeniser__tokenise__index.index
                                                       :=
                                                       ( ([sloc:mystringtokeniser.adb:46] 
                                                         ([GP_Shape:L_1_while__L_2_while__index_assign__add]
                                                         [vc:annotation]
                                                         [GP_Reason:VC_OVERFLOW_CHECK]
                                                         [GP_Sloc:mystringtokeniser.adb:46:28]
                                                         [GP_Id:1]
                                                         [comment:            Index := Index + 1;                            ^ mystringtokeniser.adb:46:28:VC_OVERFLOW_CHECK] (
                                                         Standard__integer.range_check_
                                                           (!Mystringtokeniser__tokenise__index.index
                                                              + 1))))))));
                                                       (* Check for the exit condition and loop statements appearing before the loop invariant of loop mystringtokeniser.adb:45 *);
                                                       (if
                                                       --pp_not NOT IMPLEMENTED
                                                       then
                                                       raise Mystringtokeniser__tokenise__L_2.L_2
                                                       )
                                                        end loop) with
                                                   | Mystringtokeniser__tokenise__L_2.L_2 
                                                   -> ()) )));
                                                   ([GP_Sloc:mystringtokeniser.adb:48:14] 
                                                   ([sloc:mystringtokeniser.adb:48] ()));
                                                   ([GP_Sloc:mystringtokeniser.adb:48:35] 
                                                   ([sloc:mystringtokeniser.adb:48] ()));
                                                   ([GP_Sloc:mystringtokeniser.adb:48:10] 
                                                   ([sloc:mystringtokeniser.adb:48] 
                                                   (if
                                                   ([sloc:mystringtokeniser.adb:48] ([branch_id=971]
                                                   _gnatprove_standard.Main.spark__branch
                                                   :=
                                                   ((_gnatprove_standard.Boolean.andb
                                                       (!Mystringtokeniser__tokenise__index.index
                                                          >= abstract ensures
                                                          { True } begin 
                                                           (let _ =
                                                          Mystringtokeniser__tokenise__s.s
                                                          in ())  end;
                                                          (Standard__string.first
                                                             Mystringtokeniser__tokenise__s.s))
                                                       (!Mystringtokeniser__tokenise__index.index
                                                          <= abstract ensures
                                                          { True } begin 
                                                           (let _ =
                                                          Mystringtokeniser__tokenise__s.s
                                                          in ())  end;
                                                          (Standard__string.last
                                                             Mystringtokeniser__tokenise__s.s)))
                                                      &&
                                                      --pp_not NOT IMPLEMENTED)));
                                                   ([branch_id=971] _gnatprove_standard.Main.spark__branch).bool__content
                                                   then
                                                   ();
                                                   ([GP_Sloc:mystringtokeniser.adb:50:13] 
                                                   ([sloc:mystringtokeniser.adb:50] ()));
                                                   ([GP_Sloc:mystringtokeniser.adb:50:29] 
                                                   ([sloc:mystringtokeniser.adb:50] ()));
                                                   ([GP_Sloc:mystringtokeniser.adb:50:26] 
                                                   ([sloc:mystringtokeniser.adb:50] (let ([mlw:proxy_symbol]
                                                   [introduced] temp___216) =
                                                   (let ([mlw:proxy_symbol]
                                                     [introduced] temp___215)
                                                     =
                                                     ( --pp_record_aggregate NOT IMPLEMENTED)
                                                     in abstract ensures
                                                     { True } begin  (let _ =
                                                                    ([mlw:proxy_symbol]
                                                                    [introduced] temp___215).Mystringtokeniser__tokenextent.__split_fields.Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start
                                                                    in ())  end;
                                                     --pp_record_update NOT IMPLEMENTED)
                                                   in (
                                                   Mystringtokeniser__tokenise__extent.extent__split_fields
                                                   :=
                                                   ([mlw:proxy_symbol]
                                                     [introduced] temp___216).Mystringtokeniser__tokenextent.__split_fields))));
                                                   ([GP_Sloc:mystringtokeniser.adb:51:13] 
                                                   ([sloc:mystringtokeniser.adb:51] ()));
                                                   ([GP_Sloc:mystringtokeniser.adb:51:27] 
                                                   ([sloc:mystringtokeniser.adb:51] (let ([mlw:proxy_symbol]
                                                   [introduced] temp___219) =
                                                   (let ([mlw:proxy_symbol]
                                                     [introduced] temp___218)
                                                     =
                                                     ( --pp_record_aggregate NOT IMPLEMENTED)
                                                     in abstract ensures
                                                     { True } begin  (let _ =
                                                                    ([mlw:proxy_symbol]
                                                                    [introduced] temp___218).Mystringtokeniser__tokenextent.__split_fields.Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length
                                                                    in ())  end;
                                                     --pp_record_update NOT IMPLEMENTED)
                                                   in (
                                                   Mystringtokeniser__tokenise__extent.extent__split_fields
                                                   :=
                                                   ([mlw:proxy_symbol]
                                                     [introduced] temp___219).Mystringtokeniser__tokenextent.__split_fields))));
                                                   ([GP_Sloc:mystringtokeniser.adb:56:66] 
                                                   ([sloc:mystringtokeniser.adb:56] 
                                                   (* Translation of an Ada loop from mystringtokeniser.adb:56 *);
                                                   (if
                                                   (((([sloc:mystringtokeniser.adb:54] 
                                                      ([GP_Shape:L_1_while__if__L_3_while__andthen__andthen__cmp__sub]
                                                      [vc:annotation]
                                                      [GP_Reason:VC_OVERFLOW_CHECK]
                                                      [comment:            while Positive'Last - Extent.Length >= Index                                 ^ mystringtokeniser.adb:54:33:VC_OVERFLOW_CHECK]
                                                      [GP_Sloc:mystringtokeniser.adb:54:33]
                                                      [GP_Id:4] (Standard__integer.range_check_
                                                                   (2147483647
                                                                    - (
                                                                    Standard__natural__rep.to_rep
                                                                    ( --pp_record_aggregate NOT IMPLEMENTED).Mystringtokeniser__tokenextent.__split_fields.Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length)))))
                                                        >= !Mystringtokeniser__tokenise__index.index)
                                                       &&
                                                       (_gnatprove_standard.Boolean.andb
                                                          (([sloc:mystringtokeniser.adb:55] 
                                                           ([GP_Sloc:mystringtokeniser.adb:55:30]
                                                           [vc:annotation]
                                                           [GP_Reason:VC_OVERFLOW_CHECK]
                                                           [comment:              and then (Index+Extent.Length >= S'First and Index+Extent.Length <= S'Last)                              ^ mystringtokeniser.adb:55:30:VC_OVERFLOW_CHECK]
                                                           [GP_Id:5]
                                                           [GP_Shape:L_1_while__if__L_3_while__andthen__andthen__and__cmp__add] (
                                                           Standard__integer.range_check_
                                                             (!Mystringtokeniser__tokenise__index.index
                                                                + (Standard__natural__rep.to_rep
                                                                    ( --pp_record_aggregate NOT IMPLEMENTED).Mystringtokeniser__tokenextent.__split_fields.Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length)))))
                                                             >= abstract
                                                             ensures
                                                             { True } begin 
                                                              (let _ =
                                                             Mystringtokeniser__tokenise__s.s
                                                             in ())  end;
                                                             (Standard__string.first
                                                                Mystringtokeniser__tokenise__s.s))
                                                          (([sloc:mystringtokeniser.adb:55] 
                                                           ([vc:annotation]
                                                           [GP_Sloc:mystringtokeniser.adb:55:65]
                                                           [GP_Reason:VC_OVERFLOW_CHECK]
                                                           [comment:              and then (Index+Extent.Length >= S'First and Index+Extent.Length <= S'Last)                                                                 ^ mystringtokeniser.adb:55:65:VC_OVERFLOW_CHECK]
                                                           [GP_Shape:L_1_while__if__L_3_while__andthen__andthen__and__cmp__add]
                                                           [GP_Id:6] (
                                                           Standard__integer.range_check_
                                                             (!Mystringtokeniser__tokenise__index.index
                                                                + (Standard__natural__rep.to_rep
                                                                    ( --pp_record_aggregate NOT IMPLEMENTED).Mystringtokeniser__tokenextent.__split_fields.Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length)))))
                                                             <= abstract
                                                             ensures
                                                             { True } begin 
                                                              (let _ =
                                                             Mystringtokeniser__tokenise__s.s
                                                             in ())  end;
                                                             (Standard__string.last
                                                                Mystringtokeniser__tokenise__s.s))))
                                                      &&
                                                      --pp_not NOT IMPLEMENTED)
                                                   then
                                                   (try
                                                   (let temp___loop_entry_223
                                                     =
                                                     --pp_record_aggregate NOT IMPLEMENTED
                                                     in
                                                     (* While loop translating the Ada loop from mystringtokeniser.adb:56 *);
                                                     ([sloc:mystringtokeniser.adb:56] 
                                                     loop
                                                       (* Check for absence of RTE in the loop invariant and variant *)
                                                       
                                                       
                                                       (* Assume implicit invariants from the loop mystringtokeniser.adb:56 *);
                                                       assume
                                                       { (_gnatprove_standard.Boolean.andb
                                                            (True /\
                                                               (Mystringtokeniser__tokenextent___axiom.dynamic_invariant
                                                                  --pp_record_aggregate NOT IMPLEMENTED
                                                                  False True
                                                                  True True)
                                                               /\ True /\
                                                               (--pp_record_aggregate NOT IMPLEMENTED.Mystringtokeniser__tokenextent.__split_fields.Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start
                                                                  = temp___loop_entry_223.Mystringtokeniser__tokenextent.__split_fields.Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start))
                                                            ((((2147483647
                                                                  - (
                                                                  Standard__natural__rep.to_rep
                                                                    ( --pp_record_aggregate NOT IMPLEMENTED).Mystringtokeniser__tokenextent.__split_fields.Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))
                                                                 >= !Mystringtokeniser__tokenise__index.index)
                                                                /\
                                                                (((!Mystringtokeniser__tokenise__index.index
                                                                    + (
                                                                    Standard__natural__rep.to_rep
                                                                    ( --pp_record_aggregate NOT IMPLEMENTED).Mystringtokeniser__tokenextent.__split_fields.Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))
                                                                    >= (
                                                                    Standard__string.first
                                                                    Mystringtokeniser__tokenise__s.s))
                                                                   /\
                                                                   ((!Mystringtokeniser__tokenise__index.index
                                                                    + (Standard__natural__rep.to_rep
                                                                    ( --pp_record_aggregate NOT IMPLEMENTED).Mystringtokeniser__tokenextent.__split_fields.Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))
                                                                    <= (
                                                                    Standard__string.last
                                                                    Mystringtokeniser__tokenise__s.s))))
                                                               /\
                                                               --pp_not NOT IMPLEMENTED)) };
                                                       (* Continuation of loop after loop invariant and variant *);
                                                       ();
                                                       ([GP_Sloc:mystringtokeniser.adb:57:16] 
                                                       ([sloc:mystringtokeniser.adb:57] ()));
                                                       ([GP_Sloc:mystringtokeniser.adb:57:33] 
                                                       ([sloc:mystringtokeniser.adb:57] ()));
                                                       ([GP_Sloc:mystringtokeniser.adb:57:30] 
                                                       ([sloc:mystringtokeniser.adb:57] (let ([mlw:proxy_symbol]
                                                       [introduced] temp___222)
                                                       =
                                                       (let ([mlw:proxy_symbol]
                                                         [introduced] temp___221)
                                                         =
                                                         ( --pp_record_aggregate NOT IMPLEMENTED)
                                                         in abstract ensures
                                                         { True } begin 
                                                          (let _ =
                                                         ([mlw:proxy_symbol]
                                                           [introduced] temp___221).Mystringtokeniser__tokenextent.__split_fields.Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length
                                                         in ())  end;
                                                         --pp_record_update NOT IMPLEMENTED)
                                                       in (
                                                       Mystringtokeniser__tokenise__extent.extent__split_fields
                                                       :=
                                                       ([mlw:proxy_symbol]
                                                         [introduced] temp___222).Mystringtokeniser__tokenextent.__split_fields))));
                                                       (* Check for the exit condition and loop statements appearing before the loop invariant of loop mystringtokeniser.adb:56 *);
                                                       (if
                                                       --pp_not NOT IMPLEMENTED
                                                       then
                                                       raise Mystringtokeniser__tokenise__L_3.L_3
                                                       )
                                                        end loop)) with
                                                   | Mystringtokeniser__tokenise__L_3.L_3 
                                                   -> ()) )));
                                                   ([GP_Sloc:mystringtokeniser.adb:60:20] 
                                                   ([sloc:mystringtokeniser.adb:60] ()));
                                                   ([GP_Sloc:mystringtokeniser.adb:60:33] 
                                                   ([sloc:mystringtokeniser.adb:60] ()));
                                                   ([GP_Sloc:mystringtokeniser.adb:60:30] 
                                                   ([sloc:mystringtokeniser.adb:60] (
                                                   Mystringtokeniser__tokenise__tokens.tokens
                                                   :=
                                                   (Mystringtokeniser__tokenise__S2b.to_array
                                                      (let ([mlw:proxy_symbol]
                                                      [introduced] temp___227)
                                                      =
                                                      (Mystringtokeniser__tokenise__S2b.of_array
                                                         !Mystringtokeniser__tokenise__tokens.tokens
                                                         (Standard__integer__rep.to_rep
                                                            Mystringtokeniser__tokenise__tokens.tokens__first)
                                                         (Standard__integer__rep.to_rep
                                                            Mystringtokeniser__tokenise__tokens.tokens__last))
                                                      in
                                                      --pp_record_update NOT IMPLEMENTED)))));
                                                   ([GP_Sloc:mystringtokeniser.adb:61:13] 
                                                   ([sloc:mystringtokeniser.adb:61] ()));
                                                   ([GP_Sloc:mystringtokeniser.adb:61:26] 
                                                   ([sloc:mystringtokeniser.adb:61] ()));
                                                   ([GP_Sloc:mystringtokeniser.adb:61:23] 
                                                   ([sloc:mystringtokeniser.adb:61] (
                                                   Mystringtokeniser__tokenise__processed.processed
                                                   :=
                                                   ( ([sloc:mystringtokeniser.adb:61] 
                                                     ([GP_Id:10]
                                                     [comment:            Processed := Processed + 1;                                    ^ mystringtokeniser.adb:61:36:VC_OVERFLOW_CHECK]
                                                     [vc:annotation]
                                                     [GP_Reason:VC_OVERFLOW_CHECK]
                                                     [GP_Sloc:mystringtokeniser.adb:61:36]
                                                     [GP_Shape:L_1_while__if__processed_assign__add] (
                                                     Standard__integer.range_check_
                                                       (!Mystringtokeniser__tokenise__processed.processed
                                                          + 1))))))));
                                                   ([GP_Sloc:mystringtokeniser.adb:64:17] 
                                                   ([sloc:mystringtokeniser.adb:64] ()));
                                                   ([GP_Sloc:mystringtokeniser.adb:64:13] 
                                                   ([sloc:mystringtokeniser.adb:64] 
                                                   (if
                                                   ([sloc:mystringtokeniser.adb:64] ([branch_id=1063]
                                                   _gnatprove_standard.Main.spark__branch
                                                   :=
                                                   (!Mystringtokeniser__tokenise__outindex.outindex
                                                      = (Standard__integer__rep.to_rep
                                                           abstract ensures
                                                           { True } begin 
                                                            (let _ =
                                                           (Mystringtokeniser__tokenise__S2b.of_array
                                                              !Mystringtokeniser__tokenise__tokens.tokens
                                                              (Standard__integer__rep.to_rep
                                                                 Mystringtokeniser__tokenise__tokens.tokens__first)
                                                              (Standard__integer__rep.to_rep
                                                                 Mystringtokeniser__tokenise__tokens.tokens__last))
                                                           in ())  end;
                                                           Mystringtokeniser__tokenise__tokens.tokens__last))));
                                                   ([branch_id=1063] _gnatprove_standard.Main.spark__branch).bool__content
                                                   then
                                                   raise Temp___exception_230
                                                    else
                                                   ();
                                                   ([GP_Sloc:mystringtokeniser.adb:68:16] 
                                                   ([sloc:mystringtokeniser.adb:68] ()));
                                                   ([GP_Sloc:mystringtokeniser.adb:68:28] 
                                                   ([sloc:mystringtokeniser.adb:68] ()));
                                                   ([GP_Sloc:mystringtokeniser.adb:68:25] 
                                                   ([sloc:mystringtokeniser.adb:68] (
                                                   Mystringtokeniser__tokenise__outindex.outindex
                                                   :=
                                                   ( ([sloc:mystringtokeniser.adb:68] 
                                                     ([GP_Id:11]
                                                     [GP_Sloc:mystringtokeniser.adb:68:37]
                                                     [vc:annotation]
                                                     [GP_Reason:VC_OVERFLOW_CHECK]
                                                     [GP_Shape:L_1_while__if__if__outindex_assign__add]
                                                     [comment:               OutIndex := OutIndex + 1;                                     ^ mystringtokeniser.adb:68:37:VC_OVERFLOW_CHECK] (
                                                     Standard__integer.range_check_
                                                       (!Mystringtokeniser__tokenise__outindex.outindex
                                                          + 1)))))))))));
                                                   ([GP_Sloc:mystringtokeniser.adb:72:13] 
                                                   ([sloc:mystringtokeniser.adb:72] ()));
                                                   ([GP_Sloc:mystringtokeniser.adb:72:22] 
                                                   ([sloc:mystringtokeniser.adb:72] ()));
                                                   ([GP_Sloc:mystringtokeniser.adb:72:30] 
                                                   ([sloc:mystringtokeniser.adb:72] ()));
                                                   ([GP_Sloc:mystringtokeniser.adb:72:19] 
                                                   ([sloc:mystringtokeniser.adb:72] (
                                                   Mystringtokeniser__tokenise__index.index
                                                   :=
                                                   ( ([sloc:mystringtokeniser.adb:72] 
                                                     ([GP_Id:12]
                                                     [comment:            Index := Index + Extent.Length;                            ^ mystringtokeniser.adb:72:28:VC_OVERFLOW_CHECK]
                                                     [vc:annotation]
                                                     [GP_Reason:VC_OVERFLOW_CHECK]
                                                     [GP_Sloc:mystringtokeniser.adb:72:28]
                                                     [GP_Shape:L_1_while__if__index_assign__add] (
                                                     Standard__integer.range_check_
                                                       (!Mystringtokeniser__tokenise__index.index
                                                          + (Standard__natural__rep.to_rep
                                                               ( --pp_record_aggregate NOT IMPLEMENTED).Mystringtokeniser__tokenextent.__split_fields.Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length)))))))))
                                                    else ())));
                                                   (* Check for the exit condition and loop statements appearing before the loop invariant of loop mystringtokeniser.adb:17 *);
                                                   (if
                                                   --pp_not NOT IMPLEMENTED
                                                   then
                                                   raise Mystringtokeniser__tokenise__L_1.L_1
                                                   )
                                                    end loop))) with
                                               | Temp___exception_230  ->
                                               ();
                                               ([GP_Sloc:mystringtokeniser.adb:65:25] 
                                               ([sloc:mystringtokeniser.adb:65] ()));
                                               ([GP_Sloc:mystringtokeniser.adb:65:22] 
                                               ([sloc:mystringtokeniser.adb:65] (
                                               Mystringtokeniser__tokenise__count.count
                                               :=
                                               !Mystringtokeniser__tokenise__processed.processed)));
                                               ([GP_Sloc:mystringtokeniser.adb:66:16] 
                                               ([sloc:mystringtokeniser.adb:66] raise Return__exc))) with
                                               | Mystringtokeniser__tokenise__L_1.L_1 
                                               -> ())
        )));
  ([GP_Sloc:mystringtokeniser.adb:75:16] ([sloc:mystringtokeniser.adb:75] ()));
  ([GP_Sloc:mystringtokeniser.adb:75:13] ([sloc:mystringtokeniser.adb:75] (
                                         Mystringtokeniser__tokenise__count.count
                                         :=
                                         !Mystringtokeniser__tokenise__processed.processed)));
  raise Return__exc with | Return__exc  -> ());
abstract ensures
{ True } begin  (let _ =
               (_gnatprove_standard.Boolean.andb
                  (!Mystringtokeniser__tokenise__count.count
                     <= ([sloc:mystringtokeniser.ads:18] ([GP_Shape:pragargs__and__cmp__typeconv__length_ref]
                                                         [GP_Sloc:mystringtokeniser.ads:18:29]
                                                         [comment:     Post => Count <= Tokens'Length and                                  --Line 1                             ^ mystringtokeniser.ads:18:29:VC_RANGE_CHECK]
                                                         [vc:annotation]
                                                         [GP_Reason:VC_RANGE_CHECK]
                                                         [GP_Id:24] (
                                                         Standard__integer.range_check_
                                                           abstract ensures
                                                           { True } begin 
                                                            (let _ =
                                                           (Mystringtokeniser__tokenise__S2b.of_array
                                                              !Mystringtokeniser__tokenise__tokens.tokens
                                                              (Standard__integer__rep.to_rep
                                                                 Mystringtokeniser__tokenise__tokens.tokens__first)
                                                              (Standard__integer__rep.to_rep
                                                                 Mystringtokeniser__tokenise__tokens.tokens__last))
                                                           in ())  end;
                                                           (_gnatprove_standard.Integer.length
                                                              (Standard__integer__rep.to_rep
                                                                 Mystringtokeniser__tokenise__tokens.tokens__first)
                                                              (Standard__integer__rep.to_rep
                                                                 Mystringtokeniser__tokenise__tokens.tokens__last))))))
                  (let index = ( any  pre {} post {} return int) in
                 (if
                 (_gnatprove_standard.Boolean.andb
                    ((Standard__integer__rep.to_rep abstract ensures
                        { True } begin  (let _ =
                                       (Mystringtokeniser__tokenise__S2b.of_array
                                          !Mystringtokeniser__tokenise__tokens.tokens
                                          (Standard__integer__rep.to_rep
                                             Mystringtokeniser__tokenise__tokens.tokens__first)
                                          (Standard__integer__rep.to_rep
                                             Mystringtokeniser__tokenise__tokens.tokens__last))
                                       in ())  end;
                        Mystringtokeniser__tokenise__tokens.tokens__first)
                       <= index)
                    (index
                       <= ([sloc:mystringtokeniser.ads:19] ([GP_Shape:pragargs__and__forall__range__add]
                                                           [vc:annotation]
                                                           [GP_Reason:VC_OVERFLOW_CHECK]
                                                           [GP_Sloc:mystringtokeniser.ads:19:50]
                                                           [comment:     (for all Index in Tokens'First..Tokens'First+(Count-1) =>           --Line 2                                                  ^ mystringtokeniser.ads:19:50:VC_OVERFLOW_CHECK]
                                                           [GP_Id:25] (
                                                           Standard__integer.range_check_
                                                             ((Standard__integer__rep.to_rep
                                                                 abstract
                                                                 ensures
                                                                 { True } begin 
                                                                  (let _ =
                                                                 (Mystringtokeniser__tokenise__S2b.of_array
                                                                    !Mystringtokeniser__tokenise__tokens.tokens
                                                                    (
                                                                    Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__first)
                                                                    (
                                                                    Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__last))
                                                                 in ())  end;
                                                                 Mystringtokeniser__tokenise__tokens.tokens__first)
                                                                + (!Mystringtokeniser__tokenise__count.count
                                                                    - 1)))))))
                 then
                 abstract ensures
                 { True } begin  (let _ =
                                ((_gnatprove_standard.Boolean.andb
                                    ((Standard__positive__rep.to_rep
                                        ( (let ([mlw:proxy_symbol]
                                        [introduced] temp___253) =
                                        (Mystringtokeniser__tokenise__S2b.of_array
                                           !Mystringtokeniser__tokenise__tokens.tokens
                                           (Standard__integer__rep.to_rep
                                              Mystringtokeniser__tokenise__tokens.tokens__first)
                                           (Standard__integer__rep.to_rep
                                              Mystringtokeniser__tokenise__tokens.tokens__last))
                                        in
                                        (Array__Int__Mystringtokeniser__tokenextent.get
                                           (Mystringtokeniser__tokenise__S2b.to_array
                                              ([mlw:proxy_symbol]
                                              [introduced] temp___253))
                                           assert
                                           { ([sloc:mystringtokeniser.ads:20] 
                                             ([vc:annotation]
                                             [GP_Sloc:mystringtokeniser.ads:20:19]
                                             [GP_Shape:pragargs__and__forall__andthen__and__cmp__selectcomp__ixdcomp]
                                             [GP_Reason:VC_INDEX_CHECK]
                                             [comment:          (Tokens(Index).Start >= S'First and                            --Line 3                   ^ mystringtokeniser.ads:20:19:VC_INDEX_CHECK]
                                             [GP_Id:26] (((Mystringtokeniser__tokenise__S2b.first
                                                             ([mlw:proxy_symbol]
                                                             [introduced] temp___253))
                                                            <= index) /\
                                                           (index
                                                              <= (Mystringtokeniser__tokenise__S2b.last
                                                                    ([mlw:proxy_symbol]
                                                                    [introduced] temp___253)))))) };
                                           index))).Mystringtokeniser__tokenextent.__split_fields.Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start)
                                       >= abstract ensures
                                       { True } begin  (let _ =
                                                      Mystringtokeniser__tokenise__s.s
                                                      in ())  end;
                                       (Standard__string.first
                                          Mystringtokeniser__tokenise__s.s))
                                    ((Standard__natural__rep.to_rep
                                        ( (let ([mlw:proxy_symbol]
                                        [introduced] temp___254) =
                                        (Mystringtokeniser__tokenise__S2b.of_array
                                           !Mystringtokeniser__tokenise__tokens.tokens
                                           (Standard__integer__rep.to_rep
                                              Mystringtokeniser__tokenise__tokens.tokens__first)
                                           (Standard__integer__rep.to_rep
                                              Mystringtokeniser__tokenise__tokens.tokens__last))
                                        in
                                        (Array__Int__Mystringtokeniser__tokenextent.get
                                           (Mystringtokeniser__tokenise__S2b.to_array
                                              ([mlw:proxy_symbol]
                                              [introduced] temp___254))
                                           assert
                                           { ([sloc:mystringtokeniser.ads:21] 
                                             ([vc:annotation]
                                             [GP_Shape:pragargs__and__forall__andthen__and__cmp__selectcomp__ixdcomp]
                                             [GP_Reason:VC_INDEX_CHECK]
                                             [GP_Sloc:mystringtokeniser.ads:21:18]
                                             [GP_Id:27]
                                             [comment:          Tokens(Index).Length > 0) and then                             --Line 4                  ^ mystringtokeniser.ads:21:18:VC_INDEX_CHECK] (
                                             ((Mystringtokeniser__tokenise__S2b.first
                                                 ([mlw:proxy_symbol]
                                                 [introduced] temp___254))
                                                <= index) /\
                                               (index
                                                  <= (Mystringtokeniser__tokenise__S2b.last
                                                        ([mlw:proxy_symbol]
                                                        [introduced] temp___254)))))) };
                                           index))).Mystringtokeniser__tokenextent.__split_fields.Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length)
                                       > 0)) &&
                                   (((Standard__natural__rep.to_rep
                                        ( (let ([mlw:proxy_symbol]
                                        [introduced] temp___255) =
                                        (Mystringtokeniser__tokenise__S2b.of_array
                                           !Mystringtokeniser__tokenise__tokens.tokens
                                           (Standard__integer__rep.to_rep
                                              Mystringtokeniser__tokenise__tokens.tokens__first)
                                           (Standard__integer__rep.to_rep
                                              Mystringtokeniser__tokenise__tokens.tokens__last))
                                        in
                                        (Array__Int__Mystringtokeniser__tokenextent.get
                                           (Mystringtokeniser__tokenise__S2b.to_array
                                              ([mlw:proxy_symbol]
                                              [introduced] temp___255))
                                           assert
                                           { ([sloc:mystringtokeniser.ads:22] 
                                             ([vc:annotation]
                                             [comment:            Tokens(Index).Length-1 <= S'Last - Tokens(Index).Start);     --Line 5                    ^ mystringtokeniser.ads:22:20:VC_INDEX_CHECK]
                                             [GP_Sloc:mystringtokeniser.ads:22:20]
                                             [GP_Reason:VC_INDEX_CHECK]
                                             [GP_Id:28]
                                             [GP_Shape:pragargs__and__forall__andthen__cmp__sub__selectcomp__ixdcomp] (
                                             ((Mystringtokeniser__tokenise__S2b.first
                                                 ([mlw:proxy_symbol]
                                                 [introduced] temp___255))
                                                <= index) /\
                                               (index
                                                  <= (Mystringtokeniser__tokenise__S2b.last
                                                        ([mlw:proxy_symbol]
                                                        [introduced] temp___255)))))) };
                                           index))).Mystringtokeniser__tokenextent.__split_fields.Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length)
                                       - 1)
                                      <= ([sloc:mystringtokeniser.ads:22] 
                                         ([GP_Sloc:mystringtokeniser.ads:22:46]
                                         [vc:annotation]
                                         [comment:            Tokens(Index).Length-1 <= S'Last - Tokens(Index).Start);     --Line 5                                              ^ mystringtokeniser.ads:22:46:VC_OVERFLOW_CHECK]
                                         [GP_Reason:VC_OVERFLOW_CHECK]
                                         [GP_Id:30]
                                         [GP_Shape:pragargs__and__forall__andthen__cmp__sub] (
                                         Standard__integer.range_check_
                                           (abstract ensures
                                              { True } begin  (let _ =
                                                             Mystringtokeniser__tokenise__s.s
                                                             in ())  end;
                                              (Standard__string.last
                                                 Mystringtokeniser__tokenise__s.s)
                                              - (Standard__positive__rep.to_rep
                                                   ( (let ([mlw:proxy_symbol]
                                                   [introduced] temp___256) =
                                                   (Mystringtokeniser__tokenise__S2b.of_array
                                                      !Mystringtokeniser__tokenise__tokens.tokens
                                                      (Standard__integer__rep.to_rep
                                                         Mystringtokeniser__tokenise__tokens.tokens__first)
                                                      (Standard__integer__rep.to_rep
                                                         Mystringtokeniser__tokenise__tokens.tokens__last))
                                                   in
                                                   (Array__Int__Mystringtokeniser__tokenextent.get
                                                      (Mystringtokeniser__tokenise__S2b.to_array
                                                         ([mlw:proxy_symbol]
                                                         [introduced] temp___256))
                                                      assert
                                                      { ([sloc:mystringtokeniser.ads:22] 
                                                        ([vc:annotation]
                                                        [GP_Reason:VC_INDEX_CHECK]
                                                        [comment:            Tokens(Index).Length-1 <= S'Last - Tokens(Index).Start);     --Line 5                                                       ^ mystringtokeniser.ads:22:55:VC_INDEX_CHECK]
                                                        [GP_Id:29]
                                                        [GP_Sloc:mystringtokeniser.ads:22:55]
                                                        [GP_Shape:pragargs__and__forall__andthen__cmp__sub__selectcomp__ixdcomp] (
                                                        ((Mystringtokeniser__tokenise__S2b.first
                                                            ([mlw:proxy_symbol]
                                                            [introduced] temp___256))
                                                           <= index) /\
                                                          (index
                                                             <= (Mystringtokeniser__tokenise__S2b.last
                                                                   ([mlw:proxy_symbol]
                                                                   [introduced] temp___256)))))) };
                                                      index))).Mystringtokeniser__tokenextent.__split_fields.Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start)))))))
                                in ())  end
                 ));
                 ( any  pre {} post
                 {((result = True) <-> --pp_universal_quantif NOT IMPLEMENTED)}
                 return bool)) in
())  end

end
